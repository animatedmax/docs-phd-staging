
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="This section contains procedures to help you install HAWQ. Install the HAWQ Binaries Installing from the RPM Release Installing from the Binary Tarball Create the gpadmin User Set the OS Parameters ..."/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="copyright" content="(C) Copyright 2005"/><meta name="DC.rights.owner" content="(C) Copyright 2005"/><meta name="DC.Type" content="topic"/><meta name="DC.Title" content="Installing HAWQ"/><meta name="DC.Relation" scheme="URI" content="../topics/HAWQInstallationandUpgrade.html"/><meta name="prodname" content=""/><meta name="version" content="2.1.0"/><meta name="release" content=""/><meta name="modification" content=""/><meta name="DC.Format" content="XHTML"/><meta name="DC.Identifier" content="installinghawq"/><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Installing HAWQ</title><meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="Content-Type" content="text/html; charset=utf-8"><!----></meta><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/pivotal.css"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" id="installinghawq"><script xmlns="http://www.w3.org/1999/xhtml" src="//use.typekit.net/clb0qji.js" type="text/javascript"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  try {
				  Typekit.load();
			  } catch (e) {
			  }
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  document.domain = "pivotal.io";
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			WebFontConfig = {
			  google: { families: [ 'Source+Sans+Pro:300italic,400italic,300,400,600:latin' ] }
			};
			(function() {
			  var wf = document.createElement('script');
			  wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
				'://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
			  wf.type = 'text/javascript';
			  wf.async = 'true';
			  var s = document.getElementsByTagName('script')[0];
			  s.parentNode.insertBefore(wf, s);
			})();
		  </script>
<table class="nav"><tbody><tr><td colspan="2"><div id="permalink"><a href="#" title="Link to this page"/></div><div id="printlink"><a href="javascript:window.print();" title="Print this page"/></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../topics/../topics/PivotalHAWQ.html" title="Pivotal HAWQ">Pivotal HAWQ</a> / <a class="navheader_parent_path" href="../topics/HAWQInstallationandUpgrade.html" title="HAWQ Installation and Upgrade">HAWQ Installation and Upgrade</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../topics/HAWQInstallationandUpgrade.html" title="HAWQ Installation and Upgrade"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">HAWQ Installation and Upgrade</span></a></span>  </div></td></tr></tbody></table>

   <h1 class="title topictitle1">Installing HAWQ</h1>

   <div class="body">
      <p class="p">This section contains procedures to help you install HAWQ.</p>

      <ul class="ul">
         <li class="li"><a class="xref" href="#installthehawqbinaries">Install the HAWQ Binaries</a>
            <ul class="ul">
               <li class="li"><a class="xref" href="#topic_srl_vth_tp">Installing from the RPM Release</a></li>

               <li class="li"><a class="xref" href="#topic_lqs_vth_tp">Installing from the Binary Tarball</a></li>

            </ul>
</li>

         <li class="li"><a class="xref" href="#creatingthegpadminuser">Create the gpadmin User</a>
         </li>

         <li class="li"><a class="xref" href="#settingtheosparameters">Set the OS Parameters</a>
            <ul class="ul">
               <li class="li"><a class="xref" href="#linux">Linux</a></li>

               <li class="li"><a class="xref" href="#rhel">RHEL</a></li>

               <li class="li"><a class="xref" href="#securityconfiguration">Security Configuration</a></li>

               <li class="li"><a class="xref" href="#xfs">XFS</a></li>

            </ul>
</li>

         <li class="li"><a class="xref" href="#editingtheconfigurationfiles">Edit the Configuration Files</a>
         </li>

         <li class="li"><a class="xref" href="#ensuringthathdfsworks">Ensure that HDFS Works</a>
         </li>

         <li class="li"><a class="xref" href="#creatingahawqinstanceonhdfswithnamenodehighavailabilityha">Create a HAWQ Instance on HDFS with Namenode High Availability (HA)</a>
         </li>

         <li class="li"><a class="xref" href="#runningabasicquery">Run a Basic Query</a>
         </li>

         <li class="li"><a class="xref" href="#troubleshooting">Troubleshooting a HAWQ Install</a>
         </li>

      </ul>

   </div>

   <div class="related-links"/>
<div class="topic nested1" id="installthehawqbinaries">
      <h2 class="title topictitle2">Install the HAWQ Binaries</h2>

      <div class="body">
         <p class="p">You can install HAWQ from an RPM release or binary tarball.</p>

      </div>

      <div class="topic nested2" id="topic_srl_vth_tp">
         <h3 class="title topictitle3">Installing from the RPM Release</h3>

         <div class="body">
            <p class="p">To install using the RPM file:</p>

            <ol class="ol" id="topic_srl_vth_tp__ol_fv5_xth_tp">
               <li class="li">Log in to the master host as <samp class="ph codeph">root</samp>.
                  <pre class="pre codeblock">$ su - root</pre>
Launch the installer using <samp class="ph codeph">rpm</samp>.
                  For example: <pre class="pre codeblock"># rpm –ivh hawq-dev-dev.x86_64.rpm</pre>
The
                  installer installs HAWQ to the default install path
                     (<span class="ph filepath">/usr/local/hawq-dev</span>), and creates the soft link
                     <span class="ph filepath">/usr/local/hawq</span> for
                     <span class="ph filepath">/usr/local/hawq-dev</span>. </li>

               <li class="li">Source the path file from your master host’s HAWQ installation directory:
                  <pre class="pre codeblock"># source /usr/local/hawq/greenplum_path.sh</pre>
</li>

               <li class="li">Create a file called <span class="ph filepath">hostfile</span> that includes host names in
                  your HAWQ system using segment hosts. Make sure there are no blank lines or extra
                  spaces. For example, if you have a standby master and three segments per host,
                  your file will look something like this:
                  <pre class="pre codeblock">smdw 
sdw1 
sdw2 
sdw3</pre>
</li>

               <li class="li">Perform the ssh key exchange by running the following command. This allows you to
                  log in to all hosts as root user without a password prompt. Use the
                     <span class="ph filepath">hostfile</span> file you used for installation.
                  <pre class="pre codeblock"># gpssh-exkeys -f hostfile</pre>

               </li>

               <li class="li">Run the following command to reference the <span class="ph filepath">hostfile </span>file you
                  just created and copy the HAWQ rpm file
                     (<span class="ph filepath">hawq-dev-dev.x86_64.rpm</span>) to all hosts:
                  <pre class="pre codeblock">gpscp -f hostfile 
hawq-dev-dev.x86_64.rpm =:~/</pre>
</li>

               <li class="li">Run the following command to install HAWQ on all hosts:
                  <pre class="pre codeblock"># gpssh -f hostfile -e "rpm -ivh hawq-dev-dev.x86_64.rpm"</pre>
</li>

            </ol>

         </div>

      </div>

      <div class="topic nested2" id="topic_lqs_vth_tp">
         <h3 class="title topictitle3">Installing from the Binary Tarball</h3>

         <div class="body">
            <p class="p">To install using the binary tarball: </p>

            <ol class="ol" id="topic_lqs_vth_tp__ol_krp_d5h_tp">
               <li class="li">Log in to the master host as root. <pre class="pre codeblock"> # su - root </pre>
</li>

               <li class="li">Copy the HAWQ tarball to the binary directory you want to install HAWQ, go to the
                  binary directory and uncompress the tarball. For example:
                  <pre class="pre codeblock"># cp /path/to/hawq-dev-dev.tar.gz /usr/local
# cd /usr/local
# tar xf hawq-dev-dev.tar.gz </pre>
A
                  HAWQ directory is generated. </li>

               <li class="li">Open the file <span class="ph filepath">/usr/local/greenplum_path.sh</span> and edit the
                     <samp class="ph codeph">GPHOME</samp> parameter to set it to
                     <span class="ph filepath">/usr/local/hawq</span>.
                  <pre class="pre codeblock"> GPHOME=/usr/local/hawq</pre>
</li>

               <li class="li">Source the path file from your master host’s HAWQ installation directory:
                  <pre class="pre codeblock"> # source /usr/local/hawq/greenplum_path.sh </pre>
</li>

               <li class="li">Create a file called <span class="ph filepath">hostfile</span> that includes host names used
                  in your HAWQ system in segment hosts format. Make sure there are no blank lines or
                  extra spaces. For example, if you have a standby mnaster and three segments per
                  host, your file will look something like this:
                  <pre class="pre codeblock">smdw
sdw1
sdw2
sdw3</pre>
</li>

               <li class="li">Perform the <samp class="ph codeph">ssh</samp> key exchange by running the following command.
                  This allows you to log in to all_hosts as root user without a password prompt. Use
                  the <span class="ph filepath">all_hosts</span> file you used for installation:
                  <pre class="pre codeblock"># gpssh-exkeys -f all_hosts</pre>
</li>

               <li class="li">Run the following commands to reference the hostfile file you just created and
                  copy the HAWQ binary directory (<span class="ph filepath">/usr/local/hawq-dev</span> ) on all
                  hosts:
                  <pre class="pre codeblock"># gpscp -r -f hostfile hawq-dev =:/usr/local/
# gpssh -f hostfile -e "ln -s  /usr/local/hawq-dev /usr/local/hawq"</pre>
</li>

            </ol>

         </div>

      </div>

   </div>

   <div class="topic nested1" id="creatingthegpadminuser">
      <h2 class="title topictitle2">Create the gpadmin User</h2>

      <div class="body">
         <ol class="ol" id="creatingthegpadminuser__ol_fhc_fct_4p">
            <li class="li">Create the <samp class="ph codeph">gpadmin</samp> user account on each host:
               <pre class="pre codeblock"># gpssh -f all_hosts -e '/usr/sbin/useradd gpadmin’ 
# gpssh –f all_hosts -e 'echo -e "changeme\nchangeme" | passwd gpadmin' </pre>
</li>

            <li class="li">Log in to the master host as <samp class="ph codeph">gpadmin</samp>:
               <pre class="pre codeblock">$ su - gpadmin</pre>
</li>

            <li class="li">Source the path file from the HAWQ installation directory:
               <pre class="pre codeblock">$ source /usr/local/hawq/greenplum_path.sh</pre>
</li>

            <li class="li">Run the following command to perform the <samp class="ph codeph">ssh</samp> key exchange to enable
               you to log in to all hosts without a password prompt as <samp class="ph codeph">gpadmin</samp>
               user. Use the <span class="ph filepath">all_hosts</span> file you used for installation:
               <pre class="pre codeblock">$ gpssh-exkeys -f all_hosts</pre>
</li>

            <li class="li">Use the <span class="keyword cmdname">gpssh</span> utility to add the above command line to the
               profile file. For example:
               <pre class="pre codeblock">$ gpssh -f all_hosts -e "echo source /usr/local/ hawq/greenplum_path.sh &gt;&gt; .bashrc"</pre>
</li>

            <li class="li">Use the <span class="keyword cmdname">gpssh</span> utility to confirm that the Pivotal software was
               installed on all hosts. Use the <span class="ph filepath">all_hosts</span> file you used for
               installation. For example:
                  <pre class="pre codeblock">$ gpssh -f all_hosts -e "ls -l $GPHOME" </pre>
<div class="note note title"><span class="notetitle">Note:</span> You may want to change the default configuration parameters in
                     <span class="ph filepath">/usr/local/ hawq/etc/hdfs-client.xml</span> for
                     <samp class="ph codeph">libhdfs3</samp>. See the topic, <a class="xref" href="HAWQConfigurationParameterReference.html">HAWQ Configuration Parameter Reference</a> . </div>
</li>

            <li class="li">Log in to the master host as <samp class="ph codeph">root</samp>:
               <pre class="pre codeblock">$ su - root </pre>
</li>

         </ol>

         <div class="note note"><span class="notetitle">Note:</span> In addition, verify that the <samp class="ph codeph">postgres</samp> user exists. If it does not,
            you may have to create it and add it into the <samp class="ph codeph">hadoop</samp> group. </div>

      </div>

   </div>

   <div class="topic nested1" id="settingtheosparameters">
      <h2 class="title topictitle2">Set the OS Parameters</h2>

      <div class="body">
         <p class="p">This topic describes the OS parameter options that you need to set up for the
            following:</p>

         <ul class="ul" id="settingtheosparameters__ul_w1c_fct_4p">
            <li class="li">Linux</li>

            <li class="li">RHEL</li>

            <li class="li">Security Configuration</li>

            <li class="li">XFS</li>

         </ul>

      </div>

      <div class="topic nested2" id="linux">
         <h3 class="title topictitle3">Linux</h3>

         <div class="body">
            <div class="note note"><span class="notetitle">Note:</span> Pivotal recommends that you do not set the <samp class="ph codeph">vm.overcommit_memory</samp>
               parameter if you run HAWQ on small memory virtual machines. If you set this
               parameter, you may encounter out of memory issues.</div>

            <p class="p">Set the following parameters in the <span class="ph filepath">/etc/sysctl.conf</span> file and
               reboot:</p>

            <pre class="pre codeblock">sysctl.kernel.shmmax = 500000000&#x2028;
sysctl.kernel.shmmni = 4096
sysctl.kernel.shmall = 4000000000
sysctl.kernel.sem = 250 512000 100 2048
sysctl.kernel.sysrq = 1&#x2028;
sysctl.kernel.core_uses_pid = 1&#x2028;
sysctl.kernel.msgmnb = 65536&#x2028;
sysctl.kernel.msgmax = 65536&#x2028;
sysctl.kernel.msgmni = 2048 
sysctl.net.ipv4.tcp_syncookies = 0
sysctl.net.ipv4.ip_forward = 0 
sysctl.net.ipv4.conf.default.accept_source_route = 0 
sysctl.net.ipv4.tcp_tw_recycle = 1 
sysctl.net.ipv4.tcp_max_syn_backlog = 200000 
sysctl.net.ipv4.conf.all.arp_filter = 1 
sysctl.net.ipv4.ip_local_port_range = 1025 65535 
sysctl.net.core.netdev_max_backlog = 200000 
sysctl.vm.overcommit_memory = 2
sysctl.fs.nr_open = 3000000
sysctl.kernel.threads-max = 798720
sysctl.kernel.pid_max = 798720
#increase network 
sysctl.net.core.rmem_max = 2097152
sysctl.net.core.wmen_max = 2097152</pre>

         </div>

      </div>

      <div class="topic nested2" id="rhel">
         <h3 class="title topictitle3">RHEL</h3>

         <div class="body">
            <p class="p">For RHEL version 6.x platforms, the above parameters do not include the
                  <samp class="ph codeph">sysctl.</samp> prefix, as follows:</p>

            <pre class="pre codeblock">kernel.shmmax = 500000000
kernel.shmmni = 4096
kernel.shmall = 4000000000
kernel.sem = 250 512000 100 2048
kernel.sysrq = 1
kernel.core_uses_pid = 1
kernel.msgmnb = 65536
kernel.msgmax = 65536
kernel.msgmni = 2048
net.ipv4.tcp_syncookies = 0 
net.ipv4.ip_forward = 0 
net.ipv4.conf.default.accept_source_route = 0 
net.ipv4.tcp_tw_recycle = 1 
net.ipv4.tcp_max_syn_backlog = 200000 
net.ipv4.conf.all.arp_filter = 1 
net.ipv4.ip_local_port_range = 1025 65535 
net.core.netdev_max_backlog = 200000 
vm.overcommit_memory = 2
fs.nr_open = 3000000
kernel.threads-max = 798720
kernel.pid_max = 798720
# increase network
net.core.rmem_max=2097152
net.core.wmem_max=2097152</pre>

         </div>

      </div>

      <div class="topic nested2" id="securityconfiguration">
         <h3 class="title topictitle3">Security Configuration</h3>

         <div class="body">
            <p class="p">After updating the <span class="ph filepath">/etc/sysctl.conf</span> file, set the following
               parameters (in the exact sequence displayed in the example) in the
                  <span class="ph filepath">/etc/security/limits.conf</span> file:</p>

            <pre class="pre codeblock">soft nofile 2900000
hard nofile 2900000
soft nproc 131072
hard nproc 131072</pre>

         </div>

      </div>

      <div class="topic nested2" id="xfs">
         <h3 class="title topictitle3">XFS</h3>

         <div class="body">
            <p class="p">XFS is the preferred file system for data storage on Linux platforms. Pivotal
               recommends the following xfs mount options:</p>

            <pre class="pre codeblock">rw,noatime,inode64,allocsize=16m</pre>

            <p class="p">You need to change the allocsize to 64k, only in the case of the master and the
               standby. To do so, change the allocsize to 64k in the <span class="ph filepath">/etc/fstab</span>
               file. Run the following commands:</p>

            <pre class="pre codeblock">&#x2028;sudo umount -l /path/to/filesystem&#x2028;
sudo mount /path/to/filesystem</pre>

            <p class="p">See the Linux manual (man) page for more information about the mount command:</p>

            <p class="p">The Linux disk I/O scheduler for disk access supports different policies, such as
               CFQ, AS, and deadline.</p>

            <p class="p">Pivotal recommends the following scheduler option:</p>

            <p class="p">To specify a scheduler, run the following:</p>

            <pre class="pre codeblock"># echo schedulername &gt; /sys/block/devname/queue/scheduler</pre>

            <p class="p">For example:</p>

            <pre class="pre codeblock"># echo deadline &gt; /sys/block/sbd/queue/scheduler</pre>

            <p class="p">Each disk device file should have a read-ahead (blockdev) value of 16384. To verify
               the read-ahead value of a disk device:</p>

            <pre class="pre codeblock"># /sbin/blockdev --getra devname</pre>

            <p class="p">For example:</p>

            <pre class="pre codeblock"> # /sbin/blockdev --getra /dev/sdb</pre>

            <p class="p">To set blockdev (read-ahead) on a device:</p>

            <pre class="pre codeblock"> # /sbin/blockdev --setra bytes devname</pre>

            <p class="p">For example:</p>

            <pre class="pre codeblock"> # /sbin/blockdev --setra 16385 /dev/sdb</pre>

            <p class="p">Refer to the Linux manual (man) page for more information about using the
                  <span class="keyword cmdname">blockdev</span> command.</p>

         </div>

      </div>

   </div>

   <div class="topic nested1" id="editingtheconfigurationfiles">
      <h2 class="title topictitle2">Edit the Configuration Files</h2>

      <div class="body">
         <p class="p">Edit the /etc/hosts file and make sure that it includes the host names and all interface
            address names for every machine participating in your HAWQ system. </p>

         <ol class="ol" id="editingtheconfigurationfiles__ol_h2b_fct_4p">
            <li class="li">Run the following command to copy the <span class="ph filepath">/etc/sysctl.conf</span> file and
                  <span class="ph filepath">/etc/security/limits.conf</span> file to the same location of all
               hosts:
                  <pre class="pre codeblock"># gpscp -f all_hosts /etc/sysctl.conf =:/etc
# gpscp -f all_hosts /etc/security/limits.conf =:/etc/security</pre>
<div class="note note"><span class="notetitle">Note:</span> You
                  may need to configure other parameters (for example, scheduler configuration) on
                  all hosts. </div>

            </li>

            <li class="li">Create or choose a directory that will serve as your master data storage area. This
               directory should have sufficient disk space for your data and be owned by the
                  <samp class="ph codeph">gpadmin</samp> user and group. For example, run the following commands
               as root:  <pre class="pre codeblock"># mkdir /data/master</pre>
</li>

            <li class="li">Change ownership of this directory to the <samp class="ph codeph">gpadmin</samp> user. For
               example: <pre class="pre codeblock"># chown -R gpadmin /data/master</pre>
</li>

            <li class="li">Using gpssh, create the master data directory location on your standby master as
               well. For example:
               <pre class="pre codeblock"># gpssh -h smdw -e 'mkdir /data/master'
# gpssh -h smdw -e 'chown -R gpadmin /data/master' </pre>
</li>

            <li class="li">Create a file called <span class="ph filepath">seg_hosts</span>. This file should have only one
               machine configured host name for each segment host. For example, if you have three
               segment hosts: <pre class="pre codeblock">sdw1
sdw2
sdw3</pre>
</li>

            <li class="li">Using <span class="keyword cmdname">gpssh</span>, create the data directory locations on all segment
               hosts at once using the <span class="ph filepath">seg_hosts</span> file you just created. For
               example:
               <pre class="pre codeblock"># gpssh -f seg_hosts -e 'mkdir /data/primary'
# gpssh -f seg_hosts -e 'chown gpadmin /data/primary'</pre>
</li>

            <li class="li">To use JBOD, create temporary directory locations for the master, standby, and all
               the segments. The following example uses two disks with the workfile names
                  <span class="ph filepath">/data1/tmp</span> and <span class="ph filepath">/data2/tmp</span>.
               <pre class="pre codeblock"># dirs="/data1/tmp /data2/tmp"
# mkdir $dirs# chown -R gpadmin $dirs.
# gpssh -h smdw -e "mkdir $dirs"
# gpssh -h smdw -e "chown -R gpadmin $dirs"
# gpssh -f seg_hosts -e "mkdir $dirs"
# gpssh -f seg_hosts -e "chown -R gpadmin $dirs"</pre>
</li>

            <li class="li">Log in to the master host as gpadmin. Make a copy of the
                  <span class="ph filepath">gpinitsystem_config</span> file to use as a starting point. For
               example:
               <pre class="pre codeblock">$ su - gpadmin$ cp 
$GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/gpconfigs/gpinitsystem_config </pre>
</li>

            <li class="li">Open the file you just copied in a text editor. Set all of the required parameters
               according to your environment. A HAWQ system must contain a master instance and at
               least two segment instances (even if setting up a single node system). The
                  <samp class="ph codeph">DATA_DIRECTORY</samp> parameter is what determines how many segments per
               host will be created. Here is an example of the required parameters in the
                  <span class="ph filepath">gpinitsystem_config</span> file:
               <pre class="pre codeblock">ARRAY_NAME="EMC GP-SQL"
SEG_PREFIX=gpseg
PORT_BASE=40000
declare -a TEMP_DIRECTORY=(/data1/tmp /data2/tmp)
declare -a DATA_DIRECTORY=(/data/primary /data/primary)
MASTER_HOSTNAME=mdw
MASTER_DIRECTORY=/data/master
MASTER_PORT=5432
TRUSTED SHELL=ssh
CHECK_POINT_SEGMENT=8
ENCODING=UNICODE
DFS_NAME=hdfs
DFS_URL=mdw:9000/gpsql </pre>
</li>

         </ol>

      </div>

   </div>

   <div class="topic nested1" id="ensuringthathdfsworks">
      <h2 class="title topictitle2">Ensure that HDFS Works</h2>

      <div class="body">
         <ol class="ol" id="ensuringthathdfsworks__ol_qz1_fct_4p">
            <li class="li">Make sure that your HDFS is working and change the following parameters in the
                  <span class="ph filepath">gpinitsystem_config</span> file:
               <pre class="pre codeblock">DFS_NAME=hdfs   
DFS_URL=namenode-host-name:8020/hawq</pre>
</li>

            <li class="li">Save and close the file.</li>

            <li class="li">Run the following command referencing the path and file name of your initialization
               configuration file (<span class="ph filepath">gpinitsystem_config</span>) and host file
                  (<span class="ph filepath">seg_hosts</span>). For example:
                  <pre class="pre codeblock">$ cd ~
$ gpinitsystem -c gpconfigs/gpinitsystem_config -h seg_hosts</pre>
<p class="p">For
                  a fully redundant system (with a standby master and a spread mirror
                  configuration), include the <samp class="ph codeph">-s</samp> and <samp class="ph codeph">-S</samp> options.
                  For example:
                  </p>
<pre class="pre codeblock">$ gpinitsystem -c gpconfigs/gpinitsystem_config -h seg_hosts -s standby_master_hostname</pre>
<p class="p">The
                  utility verifies your setup information and ensures that it can connect to each
                  host and access the data directories specified in your configuration. If all of
                  the pre-checks are successful, the utility prompts you to confirm your
                  configuration. For
                  example:</p>
<pre class="pre codeblock">=&gt; Continue with Greenplum creation? Yy/Nn 
Press y to start the initialization.</pre>
<p class="p">The
                  utility begins setup and initialization of the master and each segment instance in
                  the system. Each segment instance is set up in parallel. Depending on the number
                  of segments, this process can take a while. </p>

            </li>

            <li class="li">Set the <samp class="ph codeph">MASTER_DATA_DIRECTORY</samp> environment variable. For example,
               add the following line to the profile of the master host:
               <pre class="pre codeblock">export MASTER_DATA_DIRECTORY=/data/master/gpseg-1 </pre>
</li>

         </ol>

      </div>

   </div>

   <div class="topic nested1" id="creatingahawqinstanceonhdfswithnamenodehighavailabilityha">
      <h2 class="title topictitle2">Create a HAWQ Instance on HDFS with Namenode High Availability (HA)</h2>

      <div class="body">
         <p class="p">Before you proceed, check that HDFS is configured with the Namenode HA feature.</p>

         <ol class="ol" id="creatingahawqinstanceonhdfswithnamenodehighavailabilityha__ol_vp1_fct_4p">
            <li class="li">Edit the  <span class="ph filepath">${GPHOME}/etc/hdfs-client.xml</span> file: <pre class="pre codeblock">&lt;property&gt;
    &lt;name&gt;dfs.nameservices&lt;/name&gt;
    &lt;value&gt;phdcluster&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.namenodes.phdcluster&lt;/name&gt;
    &lt;value&gt;nn1,nn2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.phdcluster.nn1&lt;/name&gt;
    &lt;value&gt;mdw:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.phdcluster.nn2&lt;/name&gt;
    &lt;value&gt;smdw:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.phdcluster.nn1&lt;/name&gt;
    &lt;value&gt;mdw:50070&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.phdcluster.nn2&lt;/name&gt;
    &lt;value&gt;smdw:50070&lt;/value&gt;
&lt;/property&gt;</pre>

               <div class="note note"><span class="notetitle">Note:</span> 
                  <ul class="ul" id="creatingahawqinstanceonhdfswithnamenodehighavailabilityha__ul_xk2_3dt_4p">
                     <li class="li">Change this file on the HAWQ master and all segments.</li>

                     <li class="li">Replace <samp class="ph codeph">phdcluster</samp> with the real service ID configured in
                        HDFS.</li>

                     <li class="li">Replace <samp class="ph codeph">mdw:9000</samp> and <samp class="ph codeph">smdw:9000</samp> with
                           <var class="keyword varname">real namenode RPC host</var> and <var class="keyword varname">port</var>
                        configured in HDFS.</li>

                     <li class="li">Replace <samp class="ph codeph">mdw:50070</samp> and <samp class="ph codeph">smdw:50070</samp> with
                           <var class="keyword varname">real namenode HTTP host</var> and <var class="keyword varname">port</var>
                        configured in HDFS.</li>

                     <li class="li">The namenodes order in the value of "dfs.ha.namenodes.phdcluster" is
                        important to the performance, especially when running on security enabled
                        HDFS.<pre class="pre codeblock">&lt;property&gt;     
	&lt;name&gt;dfs.ha.namenodes.phdcluster&lt;/name&gt;     
	&lt;value&gt;nn1,nn2&lt;/value&gt; 
&lt;/property&gt;</pre>

                     </li>

                     <li class="li">To best handle failovers, the active namenode should be
                           <samp class="ph codeph">nn1</samp>. If you suspect <samp class="ph codeph">nn2</samp> is the active
                        namenode, check "dfs.ha.namenodes.phdcluster " and verify that the active
                        namenode is <samp class="ph codeph">nn1</samp> and not <samp class="ph codeph">nn2</samp>. If it is not,
                        reorder the values in "dfs.ha.namenodes.phdcluster ".<p class="p">If this parameter is
                           changed, please make sure it is changed on the HAWQ master and all
                           segments. </p>
</li>

                  </ul>

               </div>

            </li>

            <li class="li">To prepare the configuration file for the command line tool,
                  <span class="keyword cmdname">gpinitsystem</span>, change the following parameters in the
                  <span class="ph filepath">gpinitsystem_config</span> file: <pre class="pre codeblock">DFS_NAME=hdfs
DFS_URL=phdcluster/path/to/hawq/data  </pre>
<div class="note note"><span class="notetitle">Note:</span> 
                  <ul class="ul" id="creatingahawqinstanceonhdfswithnamenodehighavailabilityha__ul_ms1_fct_4p">
                     <li class="li">Replace <samp class="ph codeph">phdcluster</samp> with the real service ID configured in
                        HDFS.</li>

                     <li class="li">Replace <span class="ph filepath">/path/to/hawq/data</span> with the the directory
                        where the user want to store the data on HDFS, and make sure it exists and
                        is writable.</li>

                  </ul>

               </div>
</li>

         </ol>

      </div>

   </div>

   <div class="topic nested1" id="runningabasicquery">
      <h2 class="title topictitle2">Run a Basic Query</h2>

      <div class="body">
         <p class="p">You can run the <samp class="ph codeph">CREATE DATABASE</samp> query to test that HAWQ is running:</p>

         <pre class="pre codeblock">changl1-mbp:gpsql changl1$ psql -d postgres
psql (8.2.15)
Type "help" for help.
postgres=# create database tpch;
CREATE DATABASE
postgres=# \c tpch
You are now connected to database "tpch" as user "changl1".
tpch=# create table t (i int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'i' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE
tpch=# \timing
Timing is on.
tpch=# insert into t select generate_series(1,100);
INSERT 0 100
Time: 311.390 ms
tpch=# select count(*) from t;
count
-------
100
(1 row)
Time: 7.266 ms</pre>

      </div>

   </div>

   <div class="topic nested1" id="troubleshooting">
      <h2 class="title topictitle2">Troubleshooting a HAWQ Install</h2>

      <div class="body">
         <p class="p">During HAWQ initialization, in a cluster with a large number of nodes,  it is possible
            that some hosts could fail. If this happens, HAWQ must be reinitialized with the failed
            hosts fixed or removed. Clean the data directories (specified in the initialization
            configuration file) before re-initialization. See <a class="xref" href="#ensuringthathdfsworks">Ensure that HDFS Works</a>
            for details. </p>

         <p class="p">If other issues occur, go to the <a class="xref" href="http://support.pivotal.io">Pivotal Customer Support</a> page.</p>


      </div>

   </div>

<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../topics/HAWQInstallationandUpgrade.html" title="HAWQ Installation and Upgrade"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">HAWQ Installation and Upgrade</span></a></span>  </div><div>
<div class="container">
  <footer class="site-footer-links">
    <div class="copyright">
      <a href="http://docs.pivotal.io" target="_blank">Pivotal Documentation</a>
      © 2014 <a href="http://www.pivotal.io/" target="_blank">Pivotal Software</a>, Inc. All Rights Reserved.
  </div>
  <div class="support">
    Need help? <a href="http://support.pivotal.io" target="_blank">Visit Support</a>
   </div>
  </footer>
</div><!--end of container-->
</div>
</body>
</html>