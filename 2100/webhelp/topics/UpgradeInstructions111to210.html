
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="Note: Before you start your upgrade; make sure you have met all the upgrade prerequisites (see Pre-Upgrade Checklist ). Follow the instructions below to upgrade your PHD system from 1.1.1 to 2.1.0: ..."/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="copyright" content="(C) Copyright 2005"/><meta name="DC.rights.owner" content="(C) Copyright 2005"/><meta name="DC.Type" content="topic"/><meta name="DC.Title" content="1.1.1 to 2.1.0 - Upgrade Instructions"/><meta name="DC.Relation" scheme="URI" content="../topics/UpgradingPHDfrom111to210.html"/><meta name="prodname" content=""/><meta name="version" content="2.1.0"/><meta name="release" content=""/><meta name="modification" content=""/><meta name="DC.Format" content="XHTML"/><meta name="DC.Identifier" content="upgradeinstructions-1.1.1to2.1.0"/><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>1.1.1 to 2.1.0 - Upgrade Instructions</title><meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="Content-Type" content="text/html; charset=utf-8"><!----></meta><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/pivotal.css"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" id="upgradeinstructions-1.1.1to2.1.0"><script xmlns="http://www.w3.org/1999/xhtml" src="//use.typekit.net/clb0qji.js" type="text/javascript"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  try {
				  Typekit.load();
			  } catch (e) {
			  }
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  document.domain = "pivotal.io";
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			WebFontConfig = {
			  google: { families: [ 'Source+Sans+Pro:300italic,400italic,300,400,600:latin' ] }
			};
			(function() {
			  var wf = document.createElement('script');
			  wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
				'://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
			  wf.type = 'text/javascript';
			  wf.async = 'true';
			  var s = document.getElementsByTagName('script')[0];
			  s.parentNode.insertBefore(wf, s);
			})();
		  </script>
<table class="nav"><tbody><tr><td colspan="2"><div id="permalink"><a href="#" title="Link to this page"/></div><div id="printlink"><a href="javascript:window.print();" title="Print this page"/></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../topics/../topics/PHDInstallationandAdministration.html" title="PHD Installation and Administration">PHD Installation and Administration</a> / <a class="navheader_parent_path" href="../topics/UpgradingPHDfrom111to210.html" title="Upgrading PHD 1.1.1 to 2.1.0">Upgrading PHD 1.1.1 to 2.1.0</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../topics/UpgradingPHDfrom111to210.html" title="Upgrading PHD 1.1.1 to 2.1.0"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Upgrading PHD 1.1.1 to 2.1.0</span></a></span>  </div></td></tr></tbody></table>

   <h1 class="title topictitle1">1.1.1 to 2.1.0 - Upgrade Instructions</h1>

   <div class="body">
      <div class="note note"><span class="notetitle">Note:</span> Before you start your upgrade; make sure you have met all the upgrade prerequisites (see
            <a class="xref" href="UpgradePrerequisiteChecklist.html#upgradeprerequisitechecklist">Pre-Upgrade Checklist</a>).</div>

      <p class="p">Follow the instructions below to upgrade your PHD system from 1.1.1 to 2.1.0:</p>

      <ol class="ol">
         <li class="li">
            <strong class="ph b">Verify the current state of the cluster:</strong>
            <ol class="ol" type="a">
               <li class="li">Using the Pivotal Command Center user interface, check to see if any services are
                  down. If any service is down or is running with errors, address those issues
                  before upgrading.</li>

               <li class="li">On one of the HDFS nodes, as <samp class="ph codeph">gpadmin</samp>, run:
                     <pre class="pre codeblock">sudo -u hdfs hdfs dfsadmin -report</pre>
<p class="p">An example of the
                     output is below.</p>
<div class="p">Make sure that there are no:<ul class="ul" id="upgradeinstructions-1.1.1to2.1.0__ul_t5b_lxg_tp">
                        <li class="li"><samp class="ph codeph">Under replicated blocks</samp>, <samp class="ph codeph">Blocks with corrupt
                              replicas</samp>, or <samp class="ph codeph">Missing blocks</samp>.</li>

                        <li class="li">Dead or decommissioned nodes: <ul class="ul">
                              <li class="li">If you have decommissioned Data Nodes, removed then from the
                                 cluster using the <samp class="ph codeph">icm_client remove-slaves</samp> command
                                 (see <a class="xref" href="ManagingaPHDCluster.html">Shrinking a
                                    Cluster</a>). You can always add them back after you have
                                 completed the upgrade procedure (see <a class="xref" href="ManagingaPHDCluster.html">Expanding a Cluster</a>).</li>

                              <li class="li">If you have dead Data Nodes, either remove then or bring them back
                                 up. </li>

                           </ul>
</li>

                     </ul>
</div>
<p class="p"><strong class="ph b">Example dfsadmin Report</strong>
                  </p>
<pre class="pre codeblock">sudo -u hdfs hdfs dfsadmin -report
Configured Capacity: 93657587712 (87.23 GB)
Present Capacity: 81391808512 (75.80 GB)
DFS Remaining: 81391706112 (75.80 GB)
DFS Used: 102400 (100 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
-------------------------------------------------
Datanodes available: 1 (1 total, 0 dead)
Live datanodes:
Name: 192.168.2.203:50010 (rhel64-3.localdomain)
Hostname: rhel64-3.localdomain
Decommission Status : Normal
Configured Capacity: 93657587712 (87.23 GB)
DFS Used: 102400 (100 KB)
Non DFS Used: 12265779200 (11.42 GB)
DFS Remaining: 81391706112 (75.80 GB)
DFS Used%: 0.00%
DFS Remaining%: 86.90%
Last contact: Fri Apr 25 18:39:22 UTC 2014</pre>
</li>

               <li class="li">Run <samp class="ph codeph">fsck</samp> and ensure that the filesystem is healthy; for example,
                  there are no corrupt files. An example of the output is below. <p class="p"><strong class="ph b">Example fsck
                        Output</strong>
                  </p>
<pre class="pre codeblock">sudo -u hdfs hdfs fsck /
Connecting to namenode via http://rhel64-3:50070
FSCK started by hdfs (auth:SIMPLE) from /192.168.2.202 for path / at Fri Apr 25 20:56:52 UTC 2014
...Status: HEALTHY
Total size: 366 B
Total dirs: 20
Total files: 3
Total symlinks: 0
Total blocks (validated): 3 (avg. block size 122 B)
Minimally replicated blocks: 3 (100.0 %)
Over-replicated blocks: 0 (0.0 %)
Under-replicated blocks: 0 (0.0 %)
Mis-replicated blocks: 0 (0.0 %)
Default replication factor: 1
Average block replication: 1.0
Corrupt blocks: 0
Missing replicas: 0 (0.0 %)
Number of data-nodes: 1
Number of racks: 1
FSCK ended at Fri Apr 25 20:56:52 UTC 2014 in 211 milliseconds

The filesystem under path '/' is HEALTHY</pre>
</li>

            </ol>

            <div class="note important"><span class="importanttitle">Important:</span> If you cannot get a cluster into a healthy state, contact Pivotal
               Support before continuing with your upgrade. </div>

         </li>

         <li class="li">
            <strong class="ph b">Back up the Hive metastore:</strong>
            <p class="p">Hive does not provide rollback options, so we recommend that you take a snapshot of
               the metastore DB before starting the upgrade: </p>

            <ol class="ol" type="a">
               <li class="li">As <samp class="ph codeph">gpadmin</samp>, log in to the machine running the Hive metastore
                  database.</li>

               <li class="li">Use the following command to backup the metastore database.Â It will back up the
                  metastore database to file <samp class="ph codeph">hive_metastore_1.backup</samp>:
                  <pre class="pre codeblock">pg_dump -U hive -p 10432 metastore &gt; hive_metastore_1.backup</pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Disable High Availability (if applicable):</strong>
            <p class="p">You cannot upgrade a version 1.1.1 cluster with High Availability enabled. Revert
               your cluster to non-HA before proceeding with an upgrade. See <a class="xref" href="HighAvailability.html">Disabling HA</a> for details. To complete this step
               for upgrades, run the following SQL command: </p>

            <pre class="pre codeblock">psql -U postgres -p 10432 gphdmgr 
-c "UPDATE cluster_properties SET property_value='false' 
WHERE cluster_id=<var class="keyword varname">&lt;cluster_id&gt;</var> AND property_name='cluster.nn.isHAEnabled';"</pre>

            <p class="p">Where: <samp class="ph codeph">&lt;cluster_id&gt;&gt;</samp> is the id of your cluster.</p>

         </li>

         <li class="li">
            <strong class="ph b">Revert to Non-Secure (if applicable):</strong>
            <p class="p">You cannot upgrade a version 1.1.1 cluster with security enabled. Revert your cluster
               to non-secure before proceeding with an upgrade. See <a class="xref" href="DisablingSecurityona111Cluster.html">Pre-Upgrade 4 - Disable Security on the Cluster (1.1.1 Upgrade Only)</a> for details.</p>

         </li>

         <li class="li">
            <strong class="ph b">For PXF, co-locate your Hive server and Name Node (if applicable):</strong>
            <p class="p">Your upgrade from PHD 1.1.1 to PHD 2.1 with PXF installed will fail if your Hive
               server is not co-located with your Name Node.Â  To co-locate these, add the
                  <samp class="ph codeph">hive.noarch</samp> package on the Name Node and copy
                  <samp class="ph codeph">hive-site.xml</samp> from the hive-server node to the Name Node machine.
            </p>

         </li>

         <li class="li">
            <strong class="ph b">Remove HAWQ Standby Master:</strong>
            <p class="p">If you have a HAWQ Standby Master, you need to remove it before you start the
               upgrade.Â  As <samp class="ph codeph">gpadmin</samp>, do the following:</p>

            <ol class="ol" type="a">
               <li class="li">Source the <samp class="ph codeph">greenplum_path.sh</samp> file:
                  <pre class="pre codeblock">$ source /usr/local/hawq/greenplum_path.sh  </pre>
</li>

               <li class="li">Remove the HAWQ Standby Master by
                     running:<pre class="pre codeblock">$ gpinitstandby -r </pre>
<p class="p">For more details, see
                        theÂ <em class="ph i">HAWQ Installation and Upgrade Guide</em>.</p>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Stop Services:</strong>
            <ol class="ol" type="a">
               <li class="li">AsÂ <samp class="ph codeph">gpadmin</samp>, stop HAWQ on the HAWQ master:
                  <pre class="pre codeblock">$ /etc/init.d/hawq stop </pre>
</li>

               <li class="li">As <samp class="ph codeph">gpadmin</samp>, stop all PHD services:
                  <pre class="pre codeblock">$ icm_client stop -l &lt;CLUSTERNAME&gt;  </pre>
</li>

               <li class="li">As <samp class="ph codeph">root</samp>, stop PCC:
                  <pre class="pre codeblock">$ service commander stopÂ   </pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Import and upgrade PCC:</strong>
            <ol class="ol" type="a">
               <li class="li">Download the new PCC file from <a class="xref" href="https://network.pivotal.io/" target="_blank">Pivotal Network</a>.</li>

               <li class="li">Copy the new PCC tarball file to your installation directory on the admin node.
                  For example:Â 
                  <pre class="pre codeblock">$ scp ./PCC-2.3.x.<strong class="ph b">version.build.os</strong>.x86_64.tar.gzÂ host:/root/phd/  </pre>
</li>

               <li class="li">Log in as <samp class="ph codeph">root</samp> and untar to that directory:Â 
                  <pre class="pre codeblock">$ cd /root/phd
$ tar --no-same-owner -zxvf PCC-2.3.x.<strong class="ph b">version.build.os</strong>.x86_64.tar.gz </pre>
</li>

               <li class="li">As <samp class="ph codeph">root</samp>, run the PCC installation script from the directory
                  where it is installed:Â  <pre class="pre codeblock">$ ./install </pre>
</li>

            </ol>

            <div class="note note"><span class="notetitle">Note:</span> There is no need to specify that this is an upgrade; the install utility
                  (<samp class="ph codeph">./install</samp>) detects whether it is a fresh install or an upgrade. </div>

            <div class="note important"><span class="importanttitle">Important:</span> The rest of the upgrade procedure is performed by the
                  <samp class="ph codeph">gpadmin</samp> user. Switch to that user now.</div>

         </li>

         <li class="li">
            <strong class="ph b">CLI Self-Upgrade:</strong>
            <div class="p">AsÂ <samp class="ph codeph">gpadmin</samp>, run the following command to upgrade the CLI:
                  <pre class="pre codeblock">$ icm_client self-upgrade</pre>
<div class="note note"><span class="notetitle">Note:</span> This command may return very
                  quickly. This does not indicate any problems and you can continue with the
                  upgrade.</div>
</div>

         </li>

         <li class="li">
            <strong class="ph b">Import new HAWQ package:</strong>
            <ol class="ol" type="a">
               <li class="li">Download and extract the new PADS (HAWQ) package from <a class="xref" href="https://network.pivotal.io/" target="_blank">Pivotal Network</a>.</li>

               <li class="li">Run:<div class="p">
                     <pre class="pre codeblock">$ icm_client import -s &lt;PATH_TO_EXTRACTED_PADS_TARBALL&gt; </pre>

                  </div>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Upgrade HAWQ:</strong>
            <div class="note important"><span class="importanttitle">Important:</span> This section is only applicable if you installed Pivotal ADS
               (HAWQ) using PHD's CLI; if you installed Pivotal ADS manually, refer to the
                  <cite class="cite">HAWQ Installation and Upgrade Guide</cite> for manual upgrade
               instructions.</div>

            <ol class="ol" type="a">
               <li class="li">To upgrade PADS (HAWQ), as <samp class="ph codeph">gpadmin</samp>, run:
                  <pre class="pre codeblock">$ icm_client upgrade -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -s pads -o <var class="keyword varname">&lt;PATH_TO_EXTRACTED_OLD_ADS_TARBALL&gt;</var>Â 
-n &lt;PATH_TO_EXTRACTED_NEW_ADS_TARBALL&gt; </pre>
</li>

               <li class="li">Optional: You can delete the old HAWQ rpm file by running:
                  <pre class="pre codeblock">$ yum erase <var class="keyword varname">&lt;HAWQ_OLD_RPM_NAME&gt;</var>Â Â  </pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Import new PRTS (for GemFire XD) package:</strong>
            <ol class="ol" type="a">
               <li class="li">Download and extract the new PRTS Â package fromÂ <a class="xref" href="https://network.pivotal.io/" target="_blank">Pivotal Network</a>.</li>

               <li class="li">Run:<div class="p">
                     <pre class="pre codeblock">$ icm_client import -s <var class="keyword varname">&lt;PATH_TO_EXTRACTED_PRTS_TARBALL&gt;</var>  </pre>

                  </div>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Upgrade PRTS (for GemFire XD):</strong>
            <div class="p">As <samp class="ph codeph">gpadmin</samp>,
               run:<pre class="pre codeblock">$ icm_client upgrade -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -s prts </pre>
</div>

         </li>

         <li class="li">
            <strong class="ph b">Import new PHD package:</strong>
            <ol class="ol" type="a">
               <li class="li">Download and extract the new PHD package from <a class="xref" href="https://network.pivotal.io/" target="_blank">Pivotal Network</a>.</li>

               <li class="li">Run:
                  <pre class="pre codeblock">$ icm_client import -s <var class="keyword varname">&lt;PATH_TO_EXTRACTED_PHD_TARBALL&gt;</var>Â Â  </pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Upgrade PHD:</strong>
            <p class="p">If your cluster is configured with HAWQ, make sure you complete upgrading Pivotal ADS
               (Upgrade HAWQ step, above), before proceeding with Pivotal HD upgrade.</p>

            <p class="p">PHD 2.x requires Oracle JDK 1.7.Â  If you are already running JDK 1.7, proceed with
               the PHD Upgrade, step b, below.Â  If you need to upgrade to JDK 1.7, first complete
               step a, below. </p>

            <ol class="ol" type="a">
               <li class="li">Import JDK:Â <p class="p">JDK 1.7 running on the Admin node is a prerequisite.Â  This step is
                     to import a downloaded JDK package that will be deployed across the cluster. </p>
<ol class="ol" type="i">
                     <li class="li">Download a supported JDK package from <a class="xref" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a>. PHD expects an RPM package; for example:
                           <span class="ph filepath">jdk-7u45-linux-x64.rpm</span>.</li>

                     <li class="li">Import the downloaded JDK package to the cluster nodes. As
                           <samp class="ph codeph">gpadmin</samp>, run:
                           <pre class="pre codeblock">$ icm_client import -r <var class="keyword varname">&lt;PATH_TO_JDK&gt;</var></pre>
<div class="note note"><span class="notetitle">Note:</span> If
                           you have manually installed UnlimitedJCEPolicy files prior to upgrading
                           your JDK, you will need to re-install them post upgrade.</div>
</li>

                  </ol>
</li>

               <li class="li">To upgrade PHD, as <samp class="ph codeph">gpadmin</samp>,
                     run:<pre class="pre codeblock">$ icm_client upgrade -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -s phd </pre>
<p class="p">If
                     you need to upgrade to JDK 1.7, include the imported JDK rpm in the upgrade
                     command (for example: <samp class="ph codeph">jdk-7u45-linux-x64.rpm</samp>) so that the
                        <samp class="ph codeph">upgrade</samp> command can deploy it to the cluster nodes:</p>
<div class="p">
                     <pre class="pre codeblock">$ icm_client upgrade -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -s phd -j ~/jdk-7u45-linux-x64.rpm </pre>

                  </div>
This upgrades the PHD stack on all cluster nodes.<div class="note note"><span class="notetitle">Note:</span> All upgrade steps,
                     including post-upgrade configuration steps described below, should be completed
                     before you re-enable HA or security on a cluster. </div>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">PXF with GemFire XD:</strong>
            <div class="p">If you have PXF using GemFire XD as a data source,
               add:<pre class="pre codeblock">'/usr/lib/gphd/gfxd/lib/gemfirexd.jar'</pre>
Â on a new line
               to:<pre class="pre codeblock">ClusterConfigDir/pxf/pxf-public.classpath </pre>
</div>

         </li>

         <li class="li">
            <strong class="ph b">Upgrade Configuration Files:</strong>
            <p class="p">After upgrading the PHD stack, you need to upgrade your cluster configuration
               files:</p>

            <ol class="ol" type="a">
               <li class="li">Fetch the new templates that come with the upgraded stack by
                     runningÂ <samp class="ph codeph">icm_client fetch-template</samp>. For example:Â  <pre class="pre codeblock">icm_client fetch-template -o ~/newTemplate</pre>
<p class="p">
                     <samp class="ph codeph">newTemplate</samp>Â is the new template for the upgraded stack without
                     any user customizations. </p>
</li>

               <li class="li">Retrieve the existing configuration from the database by running
                     <samp class="ph codeph">icm_client fetch-configuration</samp>. For example: <pre class="pre codeblock">icm_client fetch-configuration -o ~/origConfiguration -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var></pre>
<p class="p">
                     <samp class="ph codeph">origConfiguration</samp> is based on user-customized template from a
                     previous installation.</p>
</li>

               <li class="li">Identify the changes between the configurations by running
                     theÂ <samp class="ph codeph">diff</samp>Â command. For example:
                     <pre class="pre codeblock">diff -ruBw newTemplate/ origConfiguration/</pre>
<p class="p">Then apply
                     those changes to the <samp class="ph codeph">newTemplate</samp>Â you retrieved.</p>
<div class="note tip"><span class="tiptitle">Tip:</span> To simplify the process of merging the existing PHD configuration
                     with the <samp class="ph codeph">newTemplate</samp>, follow these steps:<ol class="ol" type="i" id="upgradeinstructions-1.1.1to2.1.0__ol_kwt_qwd_4p">
                        <li class="li">Overwrite <samp class="ph codeph">clusterConfig.xml</samp> in
                              <samp class="ph codeph">newTemplate</samp> with the one from the
                              <samp class="ph codeph">origConfiguration</samp> directory:
                           <pre class="pre codeblock">cp ~/origConfiguration/clusterConfig.xml Â ~/newTemplate/clusterConfig.xml </pre>
</li>

                        <li class="li">Change the value of <samp class="ph codeph">&lt;gphdStackVer&gt;</samp> to
                              <samp class="ph codeph">PHD-2.1.0.0</samp> in the
                              <samp class="ph codeph">~/newTemplate/clusterConfig.xml</samp> file.</li>

                        <li class="li">If you have explicitly modified any properties from PHD services
                           configuration files, such as <samp class="ph codeph">hdfs/hdfs-site.xml</samp>,
                              <samp class="ph codeph">yarn/yarn-site.xml</samp>, etc., then make the corresponding
                           changes to these configuration files under
                              theÂ <samp class="ph codeph">~newTemplate/</samp> directory. </li>

                     </ol>
</div>
</li>

               <li class="li">This step is only required if <samp class="ph codeph">gpxf</samp> was a configured service in
                  the existing cluster configuration.<p class="p">Make the following changes to
                        <samp class="ph codeph">clusterConfig.xml</samp> in your <samp class="ph codeph">newTemplate</samp>
                     directory:</p>
<ol class="ol" type="i">
                     <li class="li">Remove <samp class="ph codeph">gpxf</samp> from the <samp class="ph codeph">&lt;services&gt;</samp>
                        list.</li>

                     <li class="li">Add <samp class="ph codeph">pxf</samp> to the <samp class="ph codeph">&lt;services&gt;</samp>
                        list.</li>

                     <li class="li">Add <samp class="ph codeph">pxf-service</samp> role to
                           <samp class="ph codeph">&lt;hostRoleMapping&gt;</samp>.</li>

                     <li class="li">Colocate the <samp class="ph codeph">pxf-service</samp> role with namenode and
                        datanode.Â <pre class="pre codeblock">&lt;pxf&gt;
&lt;pxf-service&gt;&lt;/pxf-service&gt; 
&lt;/pxf&gt;</pre>
</li>

                     <li class="li">Delete the <samp class="ph codeph">gpxf</samp> directory from
                           <samp class="ph codeph">newTemplate</samp>
                        directory:<pre class="pre codeblock">$ rm -rf newTemplate/gpxf</pre>
</li>

                     <li class="li">Add the new PXF template to <samp class="ph codeph">newTemplate</samp>. You can do this
                        by fetching the new template and copying the <samp class="ph codeph">pxf</samp> directory
                        from the template.<p class="p">For example, as <samp class="ph codeph">gpadmin</samp>,
                        run:</p>
<pre class="pre codeblock">$ mkdir new_template 
$ icm_client fetch-template -o new_template
$ cp -r new_template/pxf <samp class="ph codeph">newTemplate</samp>       </pre>
</li>

                  </ol>
</li>

               <li class="li">Change the <samp class="ph codeph">&lt;gphdVersion&gt;</samp> field to <samp class="ph codeph">PHD-
                     2.1.0.0</samp>. </li>

               <li class="li">Upgrade services by specifying the cluster configuration directory
                     asÂ <samp class="ph codeph">~/newTemplate</samp>Â with your updated contents:
                  <pre class="pre codeblock">icm_client reconfigure -c ~/newTemplate -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -f </pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Upgrade HDFS:</strong>
            <div class="note note"><span class="notetitle">Note:</span> If you are performing the upgrade on an EMC Data Computing Appliance (DCA), you
               need to make sure that the gpadmin user has read access to each of the subdirectories
               of the NameNode name directories. The location of the NameNode name directories is
               specified in the value of the <samp class="ph codeph">dfs.namenode.name.dir</samp> property in
                  <span class="ph filepath">/etc/gphd/hadoop/conf/hdfs-site.xml</span> on the NameNode.<p class="p">For
                  example, if /<samp class="ph codeph">data/nn/dfs/name</samp> is the NameNode directory, then the
                     <samp class="ph codeph">gpadmin</samp> user must have read access to <samp class="ph codeph">data</samp>,
                     <samp class="ph codeph">nn</samp> , <samp class="ph codeph">dfs</samp> and <samp class="ph codeph">name</samp>
                  directories.</p>
</div>

            <p class="p">As <samp class="ph codeph">gpadmin</samp>, on the Admin node, do the following:</p>

            <ol class="ol" type="a">
               <li class="li">Backup the NameNode metadata by running:
                  <pre class="pre codeblock">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -o backupNNMetadata -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_1_0_0</pre>
</li>

               <li class="li">Run the NameNode upgrade by running:
                  <pre class="pre codeblock">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -o nnupgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_1_0_0</pre>
</li>

               <li class="li">Run the DataNode upgrade by running:
                  <pre class="pre codeblock">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -o dnupgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_1_0_0</pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Restart the cluster:</strong>
            <p class="p">As <samp class="ph codeph">gpadmin</samp>, run: </p>

            <pre class="pre codeblock">$ icm_client restart -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var>  </pre>

         </li>

         <li class="li">
            <strong class="ph b">Post-Upgrade HAWQ:</strong>
            <ol class="ol" type="a">
               <li class="li">Before you perform the following tasks, if you have MADlib dependencies, see the
                     <em class="ph i">HAWQ Installation and Upgrade Guide</em> for instructions for upgrading
                  MADlib.</li>

               <li class="li">On the HAWQ master node, asÂ  <samp class="ph codeph">gpadmin</samp>, run the following commands
                  toÂ migrate data:Â 
                     <pre class="pre codeblock">su - gpadmin
source /usr/lib/gphd/hawq/greenplum_path.sh
gpmigrator &lt;old_HAWQHOME_path&gt; &lt;new_HAWQHOME_path&gt; # Look into ls -laF /usr/local and find the old and new homes.

# For example:
gpmigrator /usr/local/hawq-1.1.4.0/ /usr/local/hawq-1.2.1.0/ -d /data1/master/gpseg-1 </pre>
<div class="note note"><span class="notetitle">Note:</span> The
                        <samp class="ph codeph">gpmigrator</samp> command also starts HAWQ.<p class="p">If you encounter
                        errors migrating HAWQ data, see the <em class="ph i">HAWQ Administrator Guide</em> for
                        help.</p>
</div>
</li>

               <li class="li">If you were utilizing a standby HAWQ master, you should have removed it before
                  the upgrade. It should now be reinitialized.<p class="p">On the HAWQ master, as
                        <samp class="ph codeph">gpadmin</samp>,
                     run:</p>
<div class="p"><pre class="pre codeblock">$ gpinitstandby -s &lt;standby_hostname&gt;</pre>
For
                     more details about these commands, see theÂ <em class="ph i">HAWQ Installation and Upgrade
                        Guide</em>.</div>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b"> Finalize the HDFS upgrade:</strong>
            <p class="p">Before you continue, you should run a few tests to make sure your data upgrade was
               successful, and then you can runÂ <samp class="ph codeph">finalizeUpgrade</samp>. </p>

            <p class="p">Once you have confirmed your cluster is working as expected, run the following
               command to finalize the upgrade process: </p>

            <pre class="pre codeblock">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l <var class="keyword varname">&lt;CLUSTERNAME&gt;</var> -o finalizeUpgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_1_0_0</pre>

            <div class="note note"><span class="notetitle">Note:</span> HBase master will not start unless the HBase upgrade is finalized. Please ensure
               HDFS upgrade is finalized before finalizing HBase upgrade.</div>

         </li>

         <li class="li">
            <strong class="ph b">Finalize HBase Upgrade:</strong>
            <ol class="ol" type="a">
               <li class="li">Check for any HFileV1 data (only HFileV2 is supported after upgrade to HBase
                  0.96). On the hbase-master, run:
                     <pre class="pre codeblock">$ sudo -u hbase hbase upgrade -check</pre>
<p class="p">If the return is
                        <samp class="ph codeph">Count of HFileV1:0</samp>, continue with the upgrade. </p>
<div class="note note"><span class="notetitle">Note:</span> As
                     part of the prerequisites, you should have already compacted all the tables on
                     the existing HBase cluster; this will have overwritten any HFile V1 data to
                     HFile V2 format.</div>
</li>

               <li class="li">Make sure Zookeeper and HDFS are running, but HBase is stopped.</li>

               <li class="li">Run: <pre class="pre codeblock">$ sudo -u hbase hbase upgrade -execute </pre>
</li>

            </ol>

         </li>

         <li class="li">
            <strong class="ph b">Reconfigure Manually-Installed Services:</strong>
            <p class="p">Services that were installed manually on an existing cluster are not upgraded by a
               CLI upgrade. After the PHD upgrade, you need to manually reconfigure these services
               to work with the upgraded PHD.Â See the <em class="ph i">PHD Stack and Tool Reference</em> for
               details. </p>

            <div class="note note"><span class="notetitle">Note:</span> Backing up the configuration files for these services is a prerequisite for this
               upgrade procedure. See the <em class="ph i">PHD Stack and Tools Reference</em> for the locations of
               these configuration files. </div>

         </li>

         <li class="li">
            <strong class="ph b">Re-enable High Availability:</strong>
            <p class="p">See <a class="xref" href="HighAvailability.html">High Availability</a> for details. Note that for fresh
               installations of PHD 2.1, high availability is enabled by default.Â For upgrades
               however, you will have to re-enable high availability.</p>

         </li>

         <li class="li">
            <strong class="ph b">Re-secure the Cluster:</strong>
            <p class="p">See <a class="xref" href="SecurityKerberosAuthentication.html">Security/Kerberos Authentication</a> for details.If you are not
               using HAWQ in a HA environment, your cluster should now be upgraded. Â </p>

         </li>

      </ol>

      <p class="p">
         <strong class="ph b">Next Task:</strong>
      </p>

      <ul class="ul">
         <li class="li">
            <strong class="ph b">For HA Clusters:</strong>
            <p class="p">For HAWQ in an HA environment, you need to move the HAWQ filespace to HA-enabled
               HDFS, as described in the next section, <a class="xref" href="MovingHAWQFilespacetoHAenabledHDFS111to210.html">1.1.1 to 2.1.0 - Move HAWQ Filespace to HA-enabled HDFS</a>.</p>

         </li>

         <li class="li">
            <strong class="ph b">For GemFire XD:</strong>
            <p class="p">Once you have upgraded PHD, you need to to reconfigure the cluster to add the GemFire
               XD (GFXD) service.Â  See <a class="xref" href="AddingRemovingServices.html">Adding/Removing Services</a> for details. </p>

         </li>

      </ul>

      <p class="p">Your cluster should now be upgraded. At this point, you should check to see if all your
         services are running and your data is intact. <a class="xref" href="RunningPHDSamplePrograms.html">Running PHD Sample Programs</a>
         provides instructions for testing the various services.</p>

   </div>

<div class="related-links"/>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../topics/UpgradingPHDfrom111to210.html" title="Upgrading PHD 1.1.1 to 2.1.0"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Upgrading PHD 1.1.1 to 2.1.0</span></a></span>  </div><div>
<div class="container">
  <footer class="site-footer-links">
    <div class="copyright">
      <a href="http://docs.pivotal.io" target="_blank">Pivotal Documentation</a>
      Â© 2014 <a href="http://www.pivotal.io/" target="_blank">Pivotal Software</a>, Inc. All Rights Reserved.
  </div>
  <div class="support">
    Need help? <a href="http://support.pivotal.io" target="_blank">Visit Support</a>
   </div>
  </footer>
</div><!--end of container-->
</div>
</body>
</html>