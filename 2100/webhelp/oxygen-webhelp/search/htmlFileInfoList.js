fil = new Array();
fil["0"]= "topics/ABORT.html@@@ABORT@@@Aborts the current transaction. Synopsis ABORT [WORK | TRANSACTION] Description ABORT rolls back the current transaction and causes all the updates made by the transaction to be discarded. This...";
fil["1"]= "topics/ALTER-AGGREGATE.html@@@ALTER AGGREGATE@@@Changes the definition of an aggregate function. Synopsis ALTER AGGREGATE name ( type [ , ... ] ) RENAME TO new_name ALTER AGGREGATE name ( type [ , ... ] ) OWNER TO new_owner ALTER AGGREGATE name...";
fil["2"]= "topics/ALTER-FUNCTION.html@@@ALTER FUNCTION@@@Changes the definition of a function. Synopsis ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] ) action [, ... ] [RESTRICT] ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype...";
fil["3"]= "topics/ALTER-OPERATOR-CLASS.html@@@ALTER OPERATOR CLASS@@@Changes the definition of an operator class. Synopsis ALTER OPERATOR CLASS name USING index_method RENAME TO newname ALTER OPERATOR CLASS name USING index_method OWNER TO newowner Description ALTER...";
fil["4"]= "topics/ALTER-OPERATOR.html@@@ALTER OPERATOR@@@Changes the definition of an operator. Synopsis ALTER OPERATOR name ( { lefttype | NONE} , { righttype | NONE} ) OWNER TO newowner Description ALTER OPERATOR changes the definition of an operator. The...";
fil["5"]= "topics/ALTER-ROLE.html@@@ALTER ROLE@@@Changes a database role (user or group). Synopsis ALTER ROLE name RENAME TO newname ALTER ROLE name RESET config_parameter ALTER ROLE name RESOURCE QUEUE { queue_name | NONE} ALTER ROLE name [ [WITH...";
fil["6"]= "topics/ALTER-TABLE.html@@@ALTER TABLE@@@Changes the definition of a table. Synopsis ALTER TABLE [ONLY] name RENAME [COLUMN] column TO new_column ALTER TABLE name RENAME TO new_name ALTER TABLE name SET SCHEMA new_schema ALTER TABLE [ONLY...";
fil["7"]= "topics/ALTER-TABLESPACE.html@@@ALTER TABLESPACE@@@Changes the definition of a tablespace. Synopsis ALTER TABLESPACE name RENAME TO newname ALTER TABLESPACE name OWNER TO newowner Description ALTER TABLESPACE changes the definition of a tablespace...";
fil["8"]= "topics/ALTER-TYPE.html@@@ALTER TYPE@@@Changes the definition of a data type. Synopsis ALTER TYPE name OWNER TO new_owner | SET SCHEMA new_schema Description ALTER TYPE changes the definition of an existing type. You can change the...";
fil["9"]= "topics/ALTER-USER.html@@@ALTER USER@@@Changes the definition of a database role (user). Synopsis ALTER USER name RENAME TO newname ALTER USER name SET config_parameter {TO | =} { value | DEFAULT} ALTER USER name RESET config_parameter...";
fil["10"]= "topics/ANALYZE.html@@@ANALYZE@@@Collects statistics about a database. Synopsis ANALYZE [VERBOSE] [ROOTPARTITION] table [ (column [, ...] ) ]] Description ANALYZE collects statistics about the contents of tables in the database, and...";
fil["11"]= "topics/AccessingPHD21.html@@@Accessing PHD 2.1@@@Download and extract the PHD package to your working directory: $&gt; tar zxvf PHD-2.1.0.0-&lt;nn&gt;.tar.gz $&gt; ls -p PHD-2.1.0.0-&lt;nn&gt; flume/ hadoop/ hbase/ hive/ oozie/ pig/ utility/ graphlab/ hamster...";
fil["12"]= "topics/AddingHoststoaCluster.html@@@Adding Hosts to a Cluster@@@If you plan to add hosts as part of adding a new service, perform the following tasks: Prepare the new hosts using the icm_client preparehosts command. Refer to Adding/Removing Services . If you...";
fil["13"]= "topics/AddingRemovingServices.html@@@Adding/Removing Services@@@Services can be added/removed using the icm_client reconfigure command. Edit the clusterConfig.xml file to add or remove services from the service list in the services tag. Edit the...";
fil["14"]= "topics/AdministeringPHDUsingtheCLI.html@@@Administering PHD Using the CLI@@@This section describes the administrative actions that can be performed via Pivotal Command Center s command line interface (CLI...";
fil["15"]= "topics/ApacheConfigurationReference.html@@@Apache Configuration Reference@@@The following table provides links to configuration resources for Apache Hadoop and its components: Component Configuration Reference Hadoop (HDFS, Yarn) http://hadoop.apache.org/docs/r2.2...";
fil["16"]= "topics/BEGIN.html@@@BEGIN@@@Starts a transaction block. Synopsis BEGIN [WORK | TRANSACTION] [SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED] [READ WRITE | READ ONLY] Description BEGIN initiates a transaction...";
fil["17"]= "topics/BackingUpandRestoringHAWQDatabases.html@@@Backing Up and Restoring HAWQ Databases@@@This chapter provides information on backing up and restoring databases in HAWQ system. As an administrator, you will need to back up and restore your database. HAWQ provides three utilities to help...";
fil["18"]= "topics/BeforeYouBeginInstallingPCC.html@@@Before You Begin Installing PCC@@@Before you begin your installation, be sure to read the PCC Release Notes for information about the latest features, improvements, resolved and known issues; as well as the latest versioning and...";
fil["19"]= "topics/BeforeYouBeginInstallingPHD.html@@@Before You Begin Installing PHD@@@Before you begin your installation, be sure to read the PHD Release Notes for information about the latest features, improvements, resolved and known issues; as well as the latest versioning and...";
fil["20"]= "topics/BestPracticesforDeployingHadoopServices.html@@@Best Practices for Deploying Hadoop Services@@@When creating your test environment, you can deploy all the Hadoop services and roles on a single node. A test cluster usually comprises 3 to 5 nodes. However, when deploying a production cluster with...";
fil["21"]= "topics/BestPracticesforSelectingHardware.html@@@Best Practices for Selecting Hardware@@@Typically, you should select your cluster node hardware based on the resource requirements of your analytics workload and overall need for data storage. It is hard to anticipate the workload that may...";
fil["22"]= "topics/CHECKPOINT.html@@@CHECKPOINT@@@Forces a transaction log checkpoint. Synopsis CHECKPOINT Description Write-Ahead Logging (WAL) puts a checkpoint in the transaction log every so often. The automatic checkpoint interval is set per...";
fil["23"]= "topics/CLOSE.html@@@CLOSE@@@Closes a cursor. Synopsis CLOSE cursor_name Description CLOSE frees the resources associated with an open cursor. After the cursor is closed, no subsequent operations are allowed on it. A cursor...";
fil["24"]= "topics/COMMIT.html@@@COMMIT@@@Commits the current transaction. Synopsis COMMIT [WORK | TRANSACTION] Description COMMIT commits the current transaction. All changes made by the transaction become visible to others and are...";
fil["25"]= "topics/COPY.html@@@COPY@@@Copies data between a file and a table. Synopsis COPY table [( column [, ...])] FROM {  file   | STDIN}      [ [WITH]        [OIDS]        [HEADER]        [DELIMITER [ AS ]   delimiter  ]        [NULL...";
fil["26"]= "topics/CREATE-AGGREGATE.html@@@CREATE AGGREGATE@@@Defines a new aggregate function. Synopsis CREATE [ORDERED] AGGREGATE name ( input_data_type [ , ... ])       ( SFUNC = sfunc ,         STYPE = state_data_type         [, PREFUNC = prefunc...";
fil["27"]= "topics/CREATE-DATABASE.html@@@CREATE DATABASE@@@Creates a new database. Synopsis CREATE DATABASE name [ [WITH] [OWNER [=] dbowner ]                      [TEMPLATE [=] template ]                      [ENCODING [=] encoding...";
fil["28"]= "topics/CREATE-EXTERNAL-TABLE.html@@@CREATE EXTERNAL TABLE@@@Defines a new external table. Synopsis CREATE [READABLE] EXTERNAL TABLE table_name       ( column_name data_type [, ...] | LIKE other_table )       LOCATION ( file:// seghost [: port ]/ path / file...";
fil["29"]= "topics/CREATE-FUNCTION.html@@@CREATE FUNCTION@@@Defines a new function. Synopsis CREATE [OR REPLACE] FUNCTION name      ( [ [ argmode ] [ argname ] argtype [, ...] ] )       [ RETURNS { [ SETOF ] rettype         | TABLE ([{ argname argtype | LIKE...";
fil["30"]= "topics/CREATE-GROUP.html@@@CREATE GROUP@@@Defines a new database role. Synopsis CREATE GROUP name [ [WITH] option [ ... ] ] where option can be: SUPERUSER | NOSUPERUSER | CREATEDB | NOCREATEDB | CREATE-ROLE | NOCREATE-ROLE | CREATEUSER...";
fil["31"]= "topics/CREATE-LANGUAGE.html@@@CREATE LANGUAGE@@@Defines a new procedural language. Synopsis CREATE [PROCEDURAL] LANGUAGE name CREATE [TRUSTED] [PROCEDURAL] LANGUAGE name HANDLER call_handler [VALIDATOR valfunction ] Description CREATE...";
fil["32"]= "topics/CREATE-OPERATOR-CLASS.html@@@CREATE OPERATOR CLASS@@@Defines a new operator class. Synopsis CREATE OPERATOR CLASS name [DEFAULT] FOR TYPE data_type USING index_method AS   {   OPERATOR strategy_number op_name [( op_type , op_type )] [RECHECK...";
fil["33"]= "topics/CREATE-OPERATOR.html@@@CREATE OPERATOR@@@Defines a new operator. Synopsis CREATE OPERATOR name (        PROCEDURE = funcname        [, LEFTARG = lefttype ] [, RIGHTARG = righttype ]        [, COMMUTATOR = com_op ] [, NEGATOR = neg_op...";
fil["34"]= "topics/CREATE-RESOURCE-QUEUE.html@@@CREATE RESOURCE QUEUE@@@Defines a new resource queue. Synopsis CREATE RESOURCE QUEUE name WITH ( queue_attribute = value [, ... ]) where queue_attribute is:    ACTIVE_STATEMENTS= integer         [ MAX_COST= float...";
fil["35"]= "topics/CREATE-ROLE.html@@@CREATE ROLE@@@Defines a new database role (user or group). Synopsis CREATE ROLE name [[WITH] option [ ... ]] where option can be: SUPERUSER | NOSUPERUSER | CREATEDB | NOCREATEDB | CREATE-ROLE | NOCREATE-ROLE...";
fil["36"]= "topics/CREATE-SCHEMA.html@@@CREATE SCHEMA@@@Defines a new schema. Synopsis CREATE SCHEMA schema_name [AUTHORIZATION username ] [ schema_element [ ... ]] CREATE SCHEMA AUTHORIZATION rolename [ schema_element [ ... ]] Description CREATE SCHEM...";
fil["37"]= "topics/CREATE-SEQUENCE.html@@@CREATE SEQUENCE@@@Defines a new sequence generator. Synopsis CREATE [TEMPORARY | TEMP] SEQUENCE name        [INCREMENT [BY] value ]        [MINVALUE minvalue | NO MINVALUE]        [MAXVALUE maxvalue | NO MAXVALUE...";
fil["38"]= "topics/CREATE-TABLE-AS.html@@@CREATE TABLE AS@@@Defines a new table from the results of a query. Synopsis CREATE [ [GLOBAL | LOCAL] {TEMPORARY | TEMP} ] TABLE table_name    [( column_name [, ...] )]    [ WITH ( storage_parameter = value...";
fil["39"]= "topics/CREATE-TABLE.html@@@CREATE TABLE@@@Defines a new table. Synopsis CREATE [[GLOBAL | LOCAL] {TEMPORARY | TEMP}] TABLE table_name ( [ { column_name data_type [ DEFAULT default_expr ]    [column_constraint [ ... ] [ ENCODING...";
fil["40"]= "topics/CREATE-TABLESPACE.html@@@CREATE TABLESPACE@@@Defines a new tablespace. Synopsis CREATE TABLESPACE tablespace_name [OWNER username ]        FILESPACE filespace_name Description CREATE TABLESPACE registers a new tablespace for your HAWQ system...";
fil["41"]= "topics/CREATE-TYPE.html@@@CREATE TYPE@@@Defines a new data type. Synopsis CREATE TYPE name AS ( attribute_name data_type [, ... ] ) CREATE TYPE name ( INPUT = input_function , OUTPUT = output_function [, RECEIVE = receive_function ] [, SEND...";
fil["42"]= "topics/CREATE-USER.html@@@CREATE USER@@@Defines a new database role with the LOGIN privilege by default. Synopsis CREATE USER name [ [WITH] option [ ... ] ] where option can be: SUPERUSER | NOSUPERUSER | CREATEDB | NOCREATEDB | CREATE-ROLE...";
fil["43"]= "topics/CREATE-VIEW.html@@@CREATE VIEW@@@Defines a new view. Synopsis CREATE [OR REPLACE] [TEMP | TEMPORARY] VIEW name        [ ( column_name [, ...] ) ]        AS query Description CREATE VIEW defines a view of a query. The view is not...";
fil["44"]= "topics/CharacterSetSupportReference.html@@@Character Set Support Reference@@@The character set support in HAWQ allows you to store text in a variety of character sets, including single-byte character sets such as the ISO 8859 series and multiple-byte character sets such as EUC...";
fil["45"]= "topics/ClientUtilityReference.html@@@Client Utility Reference@@@This section provides references for the command-line client utilities provided with HAWQ. HAWQ provides the standard client and server programs, and additional client utilities to administer...";
fil["46"]= "topics/ClusterAnalysis.html@@@Cluster Analysis@@@The Cluster Analysis screen provides detailed metrics about your Pivotal HD cluster. It provides cluster-wide metrics all the way down to host-level metrics. It provides Hadoop-specific metrics, as...";
fil["47"]= "topics/ClusterConfiguration.html@@@5. Cluster Configuration@@@This page displays a list of all configuration files that define this cluster; the clusterConfig.xml (to edit service configuration global values) as well as the service specific configuration files...";
fil["48"]= "topics/ClusterStatusPage.html@@@Cluster Status Page@@@Once you have launched Command Center, the initial screen you see is the Cluster Status screen. This displays a list of available clusters to monitor, the status of each cluster ( started , stopped...";
fil["49"]= "topics/ClusterTopology.html@@@4. Cluster Topology@@@The Cluster Topology screen opens. This is the screen where you specify the roles to be installed on the hosts. For example, you can specify where your Hadoop NameNode, DataNode, and so on, should be...";
fil["50"]= "topics/CommandLineInstallationFeatures.html@@@Command Line Installation Features@@@Using Pivotal Command Center s CLI to install Pivotal HD provides the following functionality: Feature Support Checking prerequisites Checks that specified hosts meet the prerequisites to install the...";
fil["51"]= "topics/CommandLineReference.html@@@Backing Up and Restoring the PCC Admin Node@@@You can back up data on the Admin node where PCC is installed. Having the backup allows you to restore the Admin node and PCC to a given state in case of failures or data corruption. Note: Backup and...";
fil["52"]= "topics/CompactHBaseTables.html@@@Pre-Upgrade 3 - Compact HBase Tables (1.1.1 Upgrade Only)@@@This step is only required if you are upgrading from PHD version 1.1.1. Before you start your upgrade you need to Compact HBase tables on the existing 0.94 cluster. For example, to compact table t1...";
fil["53"]= "topics/ConfiguringClientAuthentication.html@@@Configuring Client Authentication@@@When HAWQ is first initialized, the system contains one predefined superuser role. This role will have the same name as the operating system user who initialized the HAWQ Database system. This role...";
fil["54"]= "topics/ConfiguringHAWQonSecureHDFS.html@@@Configuring HAWQ on Secure HDFS@@@A secure HDFS installation HDFS on wire encryption ( dfs.encrypt.data.transfer ) MUST be set to false . A new un-initialized HAWQ instance or a stopped already initialized HAWQ instance that was...";
fil["55"]= "topics/ConfiguringHCatalogWebHCatonSecureHive.html@@@Configuring HCatalog (WebHCat) on Secure Hive@@@HCatalog is a tool that operates on the Hive metastore. If you want to use the HCatalog RESTFul APIs (WebHCat), security configuration is required to enable the security functionality of the WebHCat...";
fil["56"]= "topics/ConfiguringKerberosAuthentication.html@@@Configuring Kerberos Authentication@@@On the versions of Red Hat Enterprise Linux that are supported by HAWQ, you can use a Kerberos authentication system to control access to HAWQ. HAWQ supports GSSAPI with Kerberos authentication...";
fil["57"]= "topics/ConfiguringKerberosandLDAP.html@@@PHD Install 2 - Configure Kerberos and LDAP@@@[Optional] Kerberos is a network authentication protocol that provides strong authentication for client/server applications using secret-key cryptography. You can configure PHD clusters to use...";
fil["58"]= "topics/ConfiguringKerberosforHDFSHighAvailability.html@@@Configuring Kerberos for HDFS High Availability@@@Note: Currently, only Quorum Journal-based storage is support for high availability. To configure Kerberos for HDFS HA, add the following Quorum Journal-based storage configuration properties to the...";
fil["59"]= "topics/ConfiguringKerberosforHDFSandYARNMapReduce.html@@@Configuring Kerberos for HDFS and YARN (MapReduce)@@@At a minimum, Kerberos provides protection against user and service spoofing attacks, and allows for enforcement of user HDFS access permissions. The installation is not difficult, but requires very...";
fil["60"]= "topics/ConfiguringLDAPAuthentication.html@@@Configuring LDAP Authentication@@@This chapter describes how to configure the LDAP authentication system and create a database user. Before Setting up LDAP Authentication Verifying the LDAP server and the LDAP DN Editing the...";
fil["61"]= "topics/ConfiguringPCCforLDAP.html@@@Configuring PCC for LDAP@@@This section describes how you can configure PCC to use an existing LDAP server for user authentication. On the PCC Admin node, navigate to the /usr/local/pivotal-cc/config directory: cd...";
fil["62"]= "topics/ConfiguringSecureFlume.html@@@Configuring Secure Flume@@@This section describes the Flume security configurations. Prerequisites Create the Flume Principal Create the Flume Keytab Files Distribute the Flume Keytab Files and Change Ownership and Permissions...";
fil["63"]= "topics/ConfiguringSecureHBase.html@@@Configuring Secure HBase@@@If you are running secure HBase, you should also also run a secure Zookeeper (see Configuring Secure Zookeeper ). You can, however, set up the HBase master and region servers to use Kerberos and test...";
fil["64"]= "topics/ConfiguringSecureHive.html@@@Configuring Secure Hive@@@The Hive MetaStore supports Kerberos authentication for Thrift clients. You can configure a standalone Hive MetaStoreServer instance to force clients to authenticate with Kerberos by setting the...";
fil["65"]= "topics/ConfiguringSecureMahout.html@@@Configuring Secure Mahout@@@Kerberos configuration is required for users submitting Mahout jobs...";
fil["66"]= "topics/ConfiguringSecureOozie.html@@@Configuring Secure Oozie@@@This section describes Oozie security configuration. Prerequisites Create the Oozie Principal Create the HTTP Principal for the Oozie Server Create the Oozie Keytab Files Copy the Oozie Keytab Files...";
fil["67"]= "topics/ConfiguringSecurePig.html@@@Configuring Secure Pig@@@Users invoking Pig must have a valid Kerberos ticket. Otherwise no Pig-specific configuration is required on secured clusers...";
fil["68"]= "topics/ConfiguringSecureSqoop.html@@@Configuring Secure Sqoop@@@Users invoking Sqoop must have a valid Kerberos ticket. Otherwise no Sqoop-specific configuration is required on secured clusers. Note that Sqoop with Hbase or Hive proper authorization must exist for...";
fil["69"]= "topics/ConfiguringSecureZookeeper.html@@@Configuring Secure Zookeeper@@@Zookeeper secure configuration for server is recommended for HBase. Zookeeper Servers Create the Zookeeper Principals Create the Zookeeper Keytab Files Distribute the Zookeeper Keytab Files Edit the...";
fil["70"]= "topics/ConfiguringandDeployingaCluster.html@@@Configuring and Deploying a Cluster@@@This section describes how to use the Add Cluster Wizard to configure and deploy a cluster...";
fil["71"]= "topics/CreateClusterDefinition.html@@@1. Create Cluster Definition@@@In the Create Cluster Definition screen: If you are configuring a new cluster, select Create a new Cluster Definition , then click Next . If you want to edit an existing cluster: Select Upload Cluster...";
fil["72"]= "topics/DEALLOCATE.html@@@DEALLOCATE@@@Deallocates a prepared statement. Synopsis DEALLOCATE [PREPARE] name Description DEALLOCATE is used to deallocate a previously prepared SQL statement. If you do not explicitly deallocate a prepared...";
fil["73"]= "topics/DECLARE.html@@@DECLARE@@@Defines a cursor. Synopsis DECLARE name [BINARY] [INSENSITIVE] [NO SCROLL] CURSOR      [{WITH | WITHOUT} HOLD]      FOR query [FOR READ ONLY] Description DECLARE allows a user to create cursors, which...";
fil["74"]= "topics/DROP-AGGREGATE.html@@@DROP AGGREGATE@@@Removes an aggregate function. Synopsis DROP AGGREGATE [IF EXISTS] name ( type [, ...] ) [CASCADE | RESTRICT] Description DROP AGGREGATE will delete an existing aggregate function. To execute this...";
fil["75"]= "topics/DROP-DATABASE.html@@@DROP DATABASE@@@Removes a database. Synopsis DROP DATABASE [IF EXISTS] name Description DROP DATABASE drops a database. It removes the catalog entries for the database and deletes the directory containing the dat...";
fil["76"]= "topics/DROP-EXTERNAL-TABLE.html@@@DROP EXTERNAL TABLE@@@Removes an external table definition. Synopsis DROP EXTERNAL [WEB] TABLE [IF EXISTS] name [CASCADE | RESTRICT] Description DROP EXTERNAL TABLE drops an existing external table definition from the...";
fil["77"]= "topics/DROP-FILESPACE.html@@@DROP FILESPACE@@@Removes a filespace. Synopsis DROP FILESPACE [IF EXISTS] filespacename Description DROP FILESPACE removes a filespace definition and its system-generated data directories from the system. A filespace...";
fil["78"]= "topics/DROP-FUNCTION.html@@@DROP FUNCTION@@@Removes a function. Synopsis DROP FUNCTION [IF EXISTS] name ( [ [argmode] [argname] argtype [, ...] ] ) [CASCADE | RESTRICT] Description DROP FUNCTION removes the definition of an existing function...";
fil["79"]= "topics/DROP-GROUP.html@@@DROP GROUP@@@Removes a database role. Synopsis DROP GROUP [IF EXISTS] name [, ...] Description DROP GROUP is an obsolete command, though still accepted for backwards compatibility. Groups (and users) have been...";
fil["80"]= "topics/DROP-OPERATOR-CLASS.html@@@DROP OPERATOR CLASS@@@Removes an operator class. Synopsis DROP OPERATOR CLASS [IF EXISTS] name USING index_method [CASCADE | RESTRICT] Description DROP OPERATOR drops an existing operator class. To execute this command you...";
fil["81"]= "topics/DROP-OPERATOR.html@@@DROP OPERATOR@@@Removes an operator. Synopsis DROP OPERATOR [IF EXISTS] name ( { lefttype | NONE} , { righttype | NONE} ) [CASCADE | RESTRICT] Description DROP OPERATOR drops an existing operator from the database...";
fil["82"]= "topics/DROP-OWNED.html@@@DROP OWNED@@@Removes database objects owned by a database role. Synopsis DROP OWNED BY name [, ...] [CASCADE | RESTRICT] Description DROP OWNED drops all the objects in the current database that are owned by one...";
fil["83"]= "topics/DROP-RESOURCE-QUEUE.html@@@DROP RESOURCE QUEUE@@@Removes a resource queue. Synopsis DROP RESOURCE QUEUE queue_name Description This command removes a workload management resource queue from HAWQ. To drop a resource queue, the queue cannot have any...";
fil["84"]= "topics/DROP-ROLE.html@@@DROP ROLE@@@Removes a database role. Synopsis DROP ROLE [IF EXISTS] name [, ...] Description DROP ROLE removes the specified role(s). To drop a superuser role, you must be a superuser yourself. To drop...";
fil["85"]= "topics/DROP-SCHEMA.html@@@DROP SCHEMA@@@Removes a schema. Synopsis DROP SCHEMA [IF EXISTS] name [, ...] [CASCADE | RESTRICT] Description DROP SCHEMA removes schemas from the database. A schema can only be dropped by its owner or...";
fil["86"]= "topics/DROP-SEQUENCE.html@@@DROP SEQUENCE@@@Removes a sequence. Synopsis DROP SEQUENCE [IF EXISTS] name [, ...] [CASCADE | RESTRICT] Description DROP SEQUENCE removes a sequence generator table. You must own the sequence to drop it (or be...";
fil["87"]= "topics/DROP-TABLE.html@@@DROP TABLE@@@Removes a table. Synopsis DROP TABLE [IF EXISTS] name [, ...] [CASCADE | RESTRICT] Description DROP TABLE removes tables from the database. Only its owner may drop a table. To empty a table of rows...";
fil["88"]= "topics/DROP-TABLESPACE.html@@@DROP TABLESPACE@@@Removes a tablespace. Synopsis DROP TABLESPACE [IF EXISTS] tablespacename Description DROP TABLESPACE removes a tablespace from the system. A tablespace can only be dropped by its owner or...";
fil["89"]= "topics/DROP-TYPE.html@@@DROP TYPE@@@Removes a data type. Synopsis DROP TYPE [IF EXISTS] name [, ...] [CASCADE | RESTRICT] Description DROP TYPE will remove a user-defined data type. Only the owner of a type can remove it. Parameters IF...";
fil["90"]= "topics/DROP-USER.html@@@DROP USER@@@Removes a database role. Synopsis DROP USER [IF EXISTS] name [, ...] Description DROP USER is an obsolete command, though still accepted for backwards compatibility. Groups (and users) have been...";
fil["91"]= "topics/DROP-VIEW.html@@@DROP VIEW@@@Removes a view. Synopsis DROP VIEW [IF EXISTS] name [, ...] [CASCADE | RESTRICT] Description DROP VIEW will remove an existing view. Only the owner of a view can remove it. Parameters IF EXISTS Do not...";
fil["92"]= "topics/DecommissionNodesOverview.html@@@Decommission Nodes Overview@@@The Hadoop distributed scale-out cluster-computing framework was inherently designed to run on commodity hardware with typical JBOD configuration (just a bunch of disks; a disk configuration where...";
fil["93"]= "topics/DecommissioningSlaveNodes.html@@@Decommissioning Slave Nodes@@@Decommissioning is required to prevent potential loss of data blocks when you shutdown/remove slave hosts from a cluster...";
fil["94"]= "topics/DecommissioningtheDataNode.html@@@Decommissioning the Data Node@@@These procedures assume that Name Node High Availability (HA) is enabled (a Pivotal best practice, and in PHD 2.1 and higher, the default configuration). If HA is not enabled, skip the additional...";
fil["95"]= "topics/DecommissioningtheYARNNodeManager.html@@@Decommissioning the YARN NodeManager@@@Previous Step: Decommissioning the Data Node Use the following procedure if YARN NodeManager daemons are running on the nodes that are being decommissioned. Note that this process is almost immediate...";
fil["96"]= "topics/DeployingtheCluster.html@@@PHD Install 7 - Deploy the Cluster@@@Pivotal HD deploys clusters using input from the cluster configuration directory. This cluster configuration directory contains files that describes the topology and configuration for the cluster...";
fil["97"]= "topics/DeploymentOptions.html@@@Deployment Options@@@The following table illustrates the deployment options and limitations:  Component CLI Install Manual Install (via RPM) Pivotal Command Center (installs the CLI)   Hadoop MR2: HDFS, YARN Pig Hive...";
fil["98"]= "topics/DeploymentStatus.html@@@7. Deployment Status@@@The Deployment Status screen appears. This screen shows the progression of the deployment. Information displayed includes: Hostname Status Role Messsages Once the deployment is complete, click Next...";
fil["99"]= "topics/DisablingHighAvailability.html@@@Disabling High Availability@@@Starting with PHD 2.1, High Availability is enabled by default for new installations. Note: HDFS commands need a Kerberos ticket when running in secure mode. See Enabling Secure Mode Commands for more...";
fil["100"]= "topics/DisablingKerberosAuthentication.html@@@Disabling Kerberos Authentication@@@To disable Kerberos authentication for a cluster: Stop the cluster: [gpadmin]# icm_client stop -l &lt;CLUSTERNAME&gt; If you have HBase installed and HBase-to-Zookeeper communication is secured (true in...";
fil["101"]= "topics/DisablingSecurityona111Cluster.html@@@Pre-Upgrade 4 - Disable Security on the Cluster (1.1.1 Upgrade Only)@@@You need to disable security before upgrading a version 1.1.1 cluster. To disable security: Stop the cluster: [gpadmin]# icm_client stop -l &lt;CLUSTERNAME&gt; If you have HBase installed and...";
fil["102"]= "topics/DistributionContents.html@@@Distribution Contents@@@Pivotal HD is a full Apache Hadoop distribution with Pivotal add-ons and a native integration with Pivotal HAWQ. The RPM distribution of PHD contains the following: Hadoop 2.2.0 Pig 0.12.0 Zookeeper...";
fil["103"]= "topics/END.html@@@END@@@Commits the current transaction. Synopsis END [WORK | TRANSACTION] Description END commits the current transaction. All changes made by the transaction become visible to others and are guaranteed to...";
fil["104"]= "topics/EPELYumRepository.html@@@EPEL Yum Repository@@@Pivotal Command Center and Pivotal HD Enterprise expect some prerequisite packages to be pre-installed on each host, depending on the software that gets deployed on a particular host. In order to have...";
fil["105"]= "topics/EXECUTE.html@@@EXECUTE@@@Executes a prepared SQL statement. Synopsis EXECUTE name [ ( parameter [, ...] ) ] Description EXECUTE is used to execute a previously prepared statement. Since prepared statements only exist for the...";
fil["106"]= "topics/EXPLAIN.html@@@EXPLAIN@@@Shows the query plan of a statement. Synopsis EXPLAIN [ANALYZE] [VERBOSE] statement Description EXPLAIN displays the query plan that the HAWQ planner generates for the supplied statement. Query plans...";
fil["107"]= "topics/EditingtheClusterConfigurationFiles.html@@@PHD Install 4 - Edit the Cluster Configuration Files@@@Pivotal provides a default Cluster configuration file ( clusterConfig.xml ) that you need to edit for your own cluster; all the cluster nodes are configured based on this configuration file. At...";
fil["108"]= "topics/EditingtheHAWQConfigurationFile.html@@@PHD Install 5 - Edit the HAWQ Configuration File@@@HAWQ system configuration is defined in hawq/gpinitsystem_config . You can override the HAWQ database default database port setting, 5432, using the MASTER_PORT parameter. You can also change the HAWQ...";
fil["109"]= "topics/EnablingAuditing.html@@@Enabling Auditing@@@You can enable auditing before deployment or re-configuration of a cluster. To enable auditing: Locate your templates directory (by default ClusterConfigDir ). This directory is created during initial...";
fil["110"]= "topics/EnablingKerberosAuthentication.html@@@Enabling Kerberos Authentication@@@To enable security on a deployed, but unsecured, cluster, you need to set up a Kerberos server, as follows. If you already have a Kerberos server set up, you do not need to run this command, but you...";
fil["111"]= "topics/EnablingReenablingHighAvailability.html@@@Enabling/Re-enabling High Availability@@@Before you enable HA for any cluster: Make sure you take into consideration our recommended Best Practices for High Availability . Checkpoint your NameNode: Stop all incoming data traffic. With the...";
fil["112"]= "topics/ExpandingHAWQ.html@@@Expanding HAWQ@@@HAWQ Segments can be expanded. Before you expand a HAWQ segment, you need to add slaves to the cluster by either: Running the add-slaves command (see Expanding a Cluster ). Manually editing the...";
fil["113"]= "topics/ExpandingaCluster.html@@@Expanding a Cluster@@@Note: Make sure you run icm_client preparehosts against the new slave hosts prior to adding them to the cluster. (See the icm_client preparehosts command example in the  Preparing the Cluster for...";
fil["114"]= "topics/ExpandingtheHAWQSystem.html@@@Expanding the HAWQ System@@@This chapter provides information on adding additional resources to an existing HAWQ system to scale performance. Planning Your HAWQ Expansion System Expansion Overview System Expansion Checklist...";
fil["115"]= "topics/FETCH.html@@@FETCH@@@Retrieves rows from a query using a cursor. Synopsis FETCH [ forward_direction { FROM | IN } ] cursorname where forward_direction can be empty or one of:     NEXT FIRST LAST ABSOLUTE count...";
fil["116"]= "topics/FQDN.html@@@Fully Qualified Domain Names (FQDN)@@@Make sure that your hostnames are fully qualified domain names (FQDN) You can either: Use the hostname command to set the FQDN:  hostname www.example.com This is for live system updates only, and...";
fil["117"]= "topics/FileLocationsandBackups.html@@@Pre-Upgrade 1 - File Locations and Backup@@@Before you begin your upgrade, make sure you do the following: PADS File Location Make note of the path to the extracted pre-upgrade PADS tarball. If you don t remember, you can just download it again...";
fil["118"]= "topics/Flume.html@@@Flume@@@About Flume Installing Flume Prerequisites Flume RPM Packages Flume Setup Flume Agent Setup Flume Configuration Using Flume Flume Configuration Example Starting/Stopping Flume Verifying the...";
fil["119"]= "topics/ForPXFwithGemFireXD.html@@@PHD Install 6 - PXF with GemFire XD@@@If you have PXF using GemFire XD (GFXD) as a data source, add  /usr/lib/gphd/gfxd/lib/gemfirexd.jar   on a new line to ClusterConfigDir/pxf/pxf-public.classpath . Next Task: PHD Install 7 - Deploy...";
fil["120"]= "topics/GRANT.html@@@GRANT@@@Defines access privileges. Synopsis GRANT { {SELECT | INSERT | UPDATE | DELETE | REFERENCES | TRIGGER } [,...] | ALL [PRIVILEGES] }     ON [TABLE] tablename [, ...]     TO { rolename | PUBLIC...";
fil["121"]= "topics/GraphLab.html@@@GraphLab@@@About GraphLab Installing GraphLab Prerequisites GraphLab RPM Packages Reconfigure YARN Virtual Memory Running an Example Using GraphLab Recommended YARN Configurations for GraphLab on Hamster...";
fil["122"]= "topics/HAWQ1211ReleaseNotes.html@@@Pivotal HAWQ 1.2.1.1 Release Notes@@@Rev: A01 Published: November 12, 2014 Contents About the Pivotal HAWQ Components What s New in the Release Supported Platforms Installation Options Upgrade Paths Resolved Issues Known Issues HAWQ and...";
fil["123"]= "topics/HAWQ121ReleaseNotes.html@@@Pivotal HAWQ 1.2.1 Release Notes@@@Rev: A03 Published: September 15, 2014 Updated: November 12, 2014 Contents About the Pivotal HAWQ Components What s New in the Release Supported Platforms Installation Options Upgrade Paths Resolved...";
fil["124"]= "topics/HAWQAdministration.html@@@HAWQ Administration@@@This guide provides information for system administrators and database superusers responsible for administering a HAWQ system. This guide provides information and instructions for configuring...";
fil["125"]= "topics/HAWQConfigurationParameterReference.html@@@HAWQ Configuration Parameter Reference@@@This table describes the configuration in the path $HAWQ_install_path/etc/hdfs-client.xml : Parameter Description Default value Comments rpc.client.timeout Timeout interval of a RPC invocation in...";
fil["126"]= "topics/HAWQDataTypes.html@@@HAWQ Data Types@@@HAWQ has a rich set of native data types available to users. Users may also define new data types using the CREATE TYPE command. This reference shows all of the built-in data types. In addition to the...";
fil["127"]= "topics/HAWQEnvironmentVariables.html@@@HAWQ Environment Variables@@@This is a reference for the environment variables to set for HAWQ. Set these in your user’s startup shell profile (such as ~/.bashrc or ~/.bash_profile ), or in /etc/profile , if you want to set them...";
fil["128"]= "topics/HAWQFilespacesandHighAvailabilityEnabledHDFS.html@@@HAWQ Filespaces and High Availability Enabled HDFS@@@In previous versions of HAWQ, you may have initialized HAWQ on HDFS without the High Availability (HA) feature. Using the current version, you can now use the HDFS NameNode HA feature. Enabling the...";
fil["129"]= "topics/HAWQInputFormatforMapReduce.html@@@HAWQ InputFormat for MapReduce@@@MapReduce is a programming model developed by Google for processing and generating large data sets on an array of commodity servers. You can use the HAWQ InputFormat option to enable MapReduce jobs to...";
fil["130"]= "topics/HAWQInstallationandUpgrade.html@@@HAWQ Installation and Upgrade@@@This guide provides information and instructions for superusers responsible for installing and configuring a HAWQ system. This guide assumes knowledge of Linux/UNIX system administration, database...";
fil["131"]= "topics/HAWQOverview.html@@@HAWQ Overview@@@This chapter describes all of the components that comprise a HAWQ system, and how they work together. About the HAWQ Architecture HAWQ Master HAWQ Segment HAWQ Storage HAWQ Interconnect Redundancy and...";
fil["132"]= "topics/HAWQQueryMonitor.html@@@HAWQ Query Monitor@@@The HAWQ Query monitor is only displayed when HAWQ is installed on the cluster. This screen displays all active queries running on the HAWQ cluster: In this release, this screen only displays active...";
fil["133"]= "topics/HAWQQueryProcessing.html@@@HAWQ Query Processing@@@You can issue queries to HAWQ similarly to any database management system (DBMS). You can connect to the database instance on the HAWQ master host by using a client application such as psql and...";
fil["134"]= "topics/HAWQServerConfigurationParameters.html@@@HAWQ Server Configuration Parameters@@@There are many configuration parameters that affect the behavior of the HAWQ system. Parameter Types and Values Setting Parameters Server Configuration Parameters add_missing_from application...";
fil["135"]= "topics/HBase.html@@@HBase@@@About HBase Installing HBase Prerequisites HBase RPM Packages HBase Master Setup HBase RegionServer Setup HBase Client Setup HBase Thrift Server Setup REST Server Setup HBase Configuration HBase...";
fil["136"]= "topics/HCatalog.html@@@HCatalog@@@About HCatalog Installing HCatalog Prerequisites HCatalog RPM Packages HCatalog Client Setup HCatalog Server Setup Webhcat Setup Webhcat Server Setup HCatalog Configuration Using HCatalog Start/Stop...";
fil["137"]= "topics/HadoopHDFS.html@@@Hadoop HDFS@@@About Hadoop HDFS Installing Hadoop HDFS Hadoop HDFS RPM Packages Prerequisites: Core Package Setup HDFS Namenode Setup HDFS Datanode Setup HDFS Secondary Namenode Setup HDFS NFS Gateway Setup HDFS...";
fil["138"]= "topics/HadoopPseudodistributedConfiguration.html@@@Hadoop Pseudo-distributed Configuration@@@About Pseudo Distribution Installing a Hadoop Pseudo-distributed Configuration Hadoop Pseudo-distributed Configuration Setup Hadoop can be run on a single-node in a pseudo-distributed mode where each...";
fil["139"]= "topics/HadoopYARN.html@@@Hadoop YARN@@@About Hadoop YARN Installing Hadoop YARN Hadoop YARN RPM Packages Prerequisites: Core Package Setup YARN ResourceManager Setup YARN NodeManager Setup Mapreduce HistoryServer Setup YARN ProxyServer...";
fil["140"]= "topics/Hamster.html@@@Hamster@@@About Hamster Installing Hamster Prerequisites Hamster RPM Packages Hamster-core Setup OpenMPI Setup Hamster-rte Setup Reconfig & Restart NodeManager Set PATH in your env Hamster Usage Hamster Service...";
fil["141"]= "topics/HighAvailability.html@@@High Availability@@@This section describes how to disable, and re-enable High Availability (HA) on a cluster.  This section also includes some best practices and command reference information for the haadmin command...";
fil["142"]= "topics/HighAvailabilityBestPractices.html@@@Best Practices for High Availability@@@Before you deploy an HA cluster, you should take the following best practices into consideration: NameNode machines: The machines on which you run the Active and Standby NameNodes should have...";
fil["143"]= "topics/HighAvailabilityCommandReference.html@@@High Availability Command Reference@@@Note: HDFS commands need a Kerberos ticket when running in secure mode. See Secure Mode Commands for more details. hdfs haadmin prints help for all subcommands and options.  &lt;serviceid&gt; is the...";
fil["144"]= "topics/Hive.html@@@Hive@@@About Hive Installing Hive Hive Components Prerequisites Hive RPM Packages Installing DB for Hive Metastore Hive MetaStore Server Setup Hive Server Setup Hive Server2 Setup Hive Configuration Hive...";
fil["145"]= "topics/HostVerification.html@@@3. Host Verification@@@The Host Verification screen opens. This step may take a few minutes, it verifies connections to the hosts you just set up. Once the Eligibilty field changes from Pending to Eligible for all hosts...";
fil["146"]= "topics/INSERT.html@@@INSERT@@@Creates new rows in a table. Synopsis INSERT INTO table [( column [, ...] )]    {DEFAULT VALUES | VALUES ( { expression | DEFAULT} [, ...] ) [, ...] | query } Description INSERT inserts new rows into...";
fil["147"]= "topics/InitializingHAWQ.html@@@Initializing HAWQ@@@Initializing HAWQ performs the following tasks: Initializes the HAWQ master and the segment hosts. Starts the HAWQ master, segments, and the underlying postgres database. You need to initialize HAWQ...";
fil["148"]= "topics/InitializingandConfiguringHAWQ.html@@@Initialize and Configure HAWQ@@@For HAWQ users: ssh to the HAWQ master. As gpadmin , run: su - gpadmin $ source /usr/local/hawq/greenplum_path.sh $ /etc/init.d/hawq init Add the IP address of your instance of Command Center to...";
fil["149"]= "topics/InitializingandStartingHAWQ.html@@@PHD Install 9 - Initialize and Start HAWQ@@@Initializing HAWQ performs the following tasks: Initializes the HAWQ master and the segment hosts. Starts the HAWQ master, segments, and the underlying postgres database. You need to initialize HAWQ...";
fil["150"]= "topics/InstallPCC.html@@@PCC Install 1 - Installation Instructions@@@Perform the following installation steps as the root user. Note: Avoid using hostnames that contain capital letters because Puppet has an issue generating certificates for domains with capital...";
fil["151"]= "topics/InstallationInstructions.html@@@Installing PCC@@@This section describes how to install PCC...";
fil["152"]= "topics/InstallationOverview.html@@@Installation Overview@@@This section provides an overview of the Pivotal HD installation process, along with some recommended best practices...";
fil["153"]= "topics/InstallingHAWQ.html@@@Installing HAWQ@@@This section contains procedures to help you install HAWQ. Install the HAWQ Binaries Installing from the RPM Release Installing from the Binary Tarball Create the gpadmin User Set the OS Parameters...";
fil["154"]= "topics/InstallingPHDUsingtheCLI.html@@@Installing PHD Using the CLI@@@This section describes how to install and configure Pivotal HD using command line interface (CLI) of Pivotal Command Center (PCC...";
fil["155"]= "topics/InstallingPivotalCommandCenter.html@@@PHD Install 1 - Install Pivotal Command Center@@@Perform the following installation steps as the root user. Note: Avoid using hostnames that contain capital letters because Puppet has an issue generating certificates for domains with capital...";
fil["156"]= "topics/InstallingtheHAWQComponents.html@@@Installing the HAWQ Components@@@This chapter describes how to install additional HAWQ components. Installing Cryptographic Functions for PostgreSQL Install pgcrypto Enable PostGIS Support Uninstalling pgcrypto Installing PL/R...";
fil["157"]= "topics/KerberosSetup.html@@@Kerberos Setup@@@This section describes how to set up Kerberos authentication. Installing the KDC Install the MIT Kerberos 5 KDC Install Kerberos Workstation and Libraries on Cluster Hosts Distribute the Kerberos...";
fil["158"]= "topics/LDAPSetup.html@@@LDAP Setup@@@This section describes how to set up sssd to allow integrated LDAP/KDC login to cluster hosts. The sssd module is a wrapper for the Linux PAM authentication module that handles login process for...";
fil["159"]= "topics/LaunchingPCC.html@@@PCC Install 3 - Launch PCC@@@To launch the PCC UI, start a browser and navigate to the host on which you installed Command Center. For example: https:// CommandCenterHost :5443 The Command Center login page is launched in your...";
fil["160"]= "topics/LaunchingtheAddClusterWizard.html@@@Launch the  Add Cluster  Wizard@@@Note: Before you can configure and deploy a cluster, make sure you have already installed the PHD Services using the CLI ( icm_client ). See Installation Instructions for details. After you have...";
fil["161"]= "topics/ListingClusters.html@@@Listing Clusters@@@Run the icm_client list command to see a list of all the installed clusters. Syntax [gpadmin]# icm_client list --help Usage: icm_client list [options] Options: -h, --help show this help message and...";
fil["162"]= "topics/ListofPHDRESTAPIs.html@@@PHD REST API List@@@Note: The API may have changed since the release. Always refer to the latest list at: https://&lt;hostname&gt;:8080/gphdmgr/api API Short Description isi-hdfs : Isilon HDFS API ISILON status system : System...";
fil["163"]= "topics/LoggingIn.html@@@Logging In@@@Launch a browser and navigate to the host on which you installed Command Center. For example: https:// CommandCenterHost :5443 The Command Center login page is launched in your browser. The default...";
fil["164"]= "topics/Logs.html@@@Logs@@@This screen displays all system logs.  The log files are grouped by date, the most recent first.  Use the Prev / Next buttons to jump to more pages of logs. Use the upper left dropdown menus to filter...";
fil["165"]= "topics/Mahout.html@@@Mahout@@@About Mahout Installing Mahout Prerequisites Mahout RPM Packages Mahout Client Setup Mahout Configuration Using Mahout Mahout is a scalable machine learning and data mining library. For more...";
fil["166"]= "topics/ManagementUtilityReference.html@@@Management Utility Reference@@@This section provides references for the command-line management utilities provided with HAWQ. HAWQ provides the standard client and server programs, and additional management utilities to administer...";
fil["167"]= "topics/ManagingHAWQ.html@@@Managing HAWQ@@@This section describes HAWQ administrative tasks you can perform via the CLI...";
fil["168"]= "topics/ManagingHAWQLogFiles.html@@@Managing HAWQ Log Files@@@HAWQ server log file output tends to be voluminous, especially at higher debug levels, and can file up quickly. These files do not need to be saved indefinitely. Administrators should rotate the log...";
fil["169"]= "topics/ManagingPHDRolesandHosts.html@@@Managing PHD Roles and Hosts@@@Pivotal HD supports starting or stopping entire clusters or individual roles on a selected hosts. If you want to start and stop the roles manually, follow these steps: You have two options when...";
fil["170"]= "topics/ManagingaPHDCluster.html@@@Managing a PHD Cluster@@@This section describes the tasks you can perform from the CLI to manage a PHD cluster...";
fil["171"]= "topics/ManuallyInstallingandUsingPivotalHD21Stack.html@@@Manually Installing and Using Pivotal HD 2.1 Stack@@@This section describes how to manually install and use all the components included with Pivotal HD 2.1...";
fil["172"]= "topics/ManuallyUpgradingPivotalHDStacktoPHD21.html@@@Manually Upgrading Pivotal HD Stack to 2.1.0@@@Pivotal HD Stack supports the following upgrade: Upgrade from PHD 1.1.1 to PHD 2.1 Upgrade from PHD 2.0.1 to PHD 2.1 This section describes how to manually upgrade your Pivotal HD stack components...";
fil["173"]= "topics/MapReduceJobMonitor.html@@@MapReduce Job Monitor@@@The Job Monitor screen tracks the MapReduce jobs that are executed in the Pivotal HD cluster when the YARN MapReduce service is running. It provides details about all, or a filtered set of MapReduce...";
fil["174"]= "topics/ModifyingHAWQUserConfiguration.html@@@Modifying HAWQ User Configuration@@@If you are using Pivotal Command Center, you must modify your HAWQ user configuration file. This is because the Admin host is not part of the HAWQ cluster. Modifying the pg_hba.conf file on the HAWQ...";
fil["175"]= "topics/MovingHAWQFilespacetoHAenabledHDFS111to210.html@@@1.1.1 to 2.1.0 - Move HAWQ Filespace to HA-enabled HDFS@@@For HAWQ in an HA environment, you need to perform the following to complete your upgrade. As HAWQ was initialized, post-upgrade, on a non-HA HDFS, you now need to move the HAWQ filespace to...";
fil["176"]= "topics/MovingHAWQFilespacetoHAenabledHDFS20xto210.html@@@2.0.x to 2.1.0 - Move HAWQ Filespace to HA-enabled HDFS@@@For HAWQ in an HA environment, you need to perform the following tasks to complete your upgrade. As HAWQ was initialized, post-upgrade, on a non-HA HDFS, you now need to move the HAWQ filespace to...";
fil["177"]= "topics/Oozie.html@@@Oozie@@@About Oozie Installing Oozie Prerequisites Oozie RPM Packages Oozie client Setup Oozie Server Setup [Optional] Oozie Configuration Oozie Environment Configuration Setup Database Using Oozie Oozie...";
fil["178"]= "topics/OverviewofApacheStackandPivotalComponents.html@@@Overview of Apache Stack and Pivotal Components@@@Pivotal HD Enterprise is an enterprise-capable, commercially supported distribution of Apache Hadoop packages targeted to traditional Hadoop deployments. Deployment/Installation Options Pivotal...";
fil["179"]= "topics/OverviewofPHD.html@@@Overview of PHD@@@Pivotal HD Enterprise is an enterprise-capable, commercially supported distribution of Apache Hadoop packages targeted to traditional Hadoop deployments. PHD Architecture About Supported Pivotal HD...";
fil["180"]= "topics/PCC230ReleaseNotes.html@@@Pivotal Command Center 2.3.0 Release Notes@@@Rev: A03 Published: September 15, 2014 Updated: November 12, 2014 Contents What’s New Installation Dashboard Cluster Analysis Improved Logging Functionality Topology PXF GFXD Online Documentation LDAP...";
fil["181"]= "topics/PCCDNSLookup.html@@@PCC Pre-Install 1 - DNS Lookup@@@Before you begin your PCC installation, verify the following: Verify that the admin host (the host on which you will be installing PCC) is able to reach every host that will be part of your cluster...";
fil["182"]= "topics/PCCDisableSELinux.html@@@PCC Pre-Install 5 - Disable SELinux@@@Before you being your installation, verify that SELinux is disabled. As root , run: # sestatus If SELinux is disabled, one of the following is returned: SELinuxstatus: disabled or SELinux status...";
fil["183"]= "topics/PCCEPELYumRepository.html@@@EPEL Yum Repository@@@Pivotal Command Center and Pivotal HD Enterprise expect some prerequisite packages to be pre-installed on each host, depending on the software that gets deployed on a particular host. In order to have...";
fil["184"]= "topics/PCCImportingthePackages.html@@@PCC Install 2 - Import the PHD Service Packages@@@Once you have Pivotal Command Center installed, you can use the import option in the icm_client tool to synchronize the PHD service RPMs and a downloaded JDK package from the specified source location...";
fil["185"]= "topics/PCCInstallationChecklist.html@@@PCC Install Checklist@@@The table below briefly describes the steps you need to take to install a cluster; more detailed instructions are provided in Installing PCC . Note that rows with   Browser   depict operations that...";
fil["186"]= "topics/PCCInstallationPrerequisites.html@@@PCC Pre-Install@@@This section provides information you ll need, as well as tasks that must be completed, before you install PCC...";
fil["187"]= "topics/PCCJAVAJDK.html@@@PCC Pre-Install 2 - JAVA JDK@@@Before you begin your installation, ensure that you are running Oracle JAVA JDK version 1.7 on the Admin node and that you are not running OpenJDK as your default JDK. Note: Version 1.7 is required...";
fil["188"]= "topics/PCCOverview.html@@@PCC Overview@@@This section provides a brief overview of Pivotal Command Center. About Pivotal Command Center Pivotal Command Center UI and CLI Performance Monitor (nmon) PostgreSQL Database Architectural Diagram...";
fil["189"]= "topics/PCCPrerequisiteChecklist.html@@@PCC Pre-Install Checklist@@@The following prerequisite tasks need to be completed before you begin your PCC installation. Each task is explained in more detail in subsequent sections; click the task name to jump to those...";
fil["190"]= "topics/PCCTurnOffiptables.html@@@PCC Pre-Install 4 - Turn Off iptables@@@Before you begin your installation, verify that iptables is turned off: As root : # chkconfig iptables off # service iptables stop Next Task: PCC Pre-Install 5 - Disable SELinux...";
fil["191"]= "topics/PCCUIDashboard.html@@@PCC UI Dashboard@@@The dashboard gives you a high level view of a cluster at a glance. You are able to view the status of the most important cluster services, such as HDFS and YARN, and can start and stop each service...";
fil["192"]= "topics/PCCUIOverview.html@@@PCC UI Overview@@@Pivotal Command Center UI is a browser-based application for configuring, deploying, administering, and monitoring Pivotal HD clusters. At a high level, the screens consist of: Cluster Status Page...";
fil["193"]= "topics/PCCUISettings.html@@@PCC UI Settings@@@Once you have logged in, you can click the gear icon in the upper right corner of the screen from any PCC page to display the Settings menu. From the settings menu you can select one of: About...";
fil["194"]= "topics/PCCUIUserManagement.html@@@PCC UI User Management@@@There are two types of users: Administrative (super user) - If you are an administrative user, you can add users, edit your own or other users  profiles, change your own or other users  passwords, and...";
fil["195"]= "topics/PCCUserGuide.html@@@PCC User Guide@@@This document provides an overview of Pivotal Command Center (PCC), as well as detailed instructions for installing and using PCC. It also provides descriptions and syntax for the command line...";
fil["196"]= "topics/PCCVerifyPackageAccessibility.html@@@PCC Pre-Install 3 - Verify Package Accessibility@@@Verify that all packages are available in a local yum repository or that you have yum access to an EPEL yum repository. Pivotal Command Center and Pivotal HD Enterprise expect some prerequisite...";
fil["197"]= "topics/PHDDNSLookup.html@@@PHD Pre-Inst 1 - DNS Lookup@@@Before you can begin your PHD installation, verify the following: Verify that the admin host (the host on which you will be installing PCC) is able to reach every host that will be part of your...";
fil["198"]= "topics/PHDDisableSELinux.html@@@PHD Pre-Inst 5 - Disable SELinux@@@Before you being your installation, verify that SELinux is disabled: As root , run: # sestatus If SELinux is disabled, one of the following is returned: SELinuxstatus: disabled or SELinux status...";
fil["199"]= "topics/PHDEnterprise210ReleaseNotes.html@@@PHD Enterprise 2.1.0 Release Notes@@@Rev: A03 Published: September 15, 2014 Updated: November 12, 2014 Contents PHD Components Core Apache Stack Pivotal and Other Components Software Requirements Java Operating System/Browser What’s New...";
fil["200"]= "topics/PHDFAQFrequentlyAskedQuestions.html@@@PHD Frequently Asked Questions (FAQ)@@@Can I deploy multiple clusters from the same admin? Yes, you can deploy any number of Pivotal HD clusters from the same admin. You must deploy them in succession, not simultaneously. Can I modify the...";
fil["201"]= "topics/PHDImportingthePackages.html@@@PHD Install 3 - Import the PHD Service Packages@@@Once you have Pivotal Command Center installed, you can use the import option of the icm_client tool to synchronize the PHD service RPMs and a downloaded JDK package from the specified source location...";
fil["202"]= "topics/PHDInstallationChecklist.html@@@PHD Installation Checklist@@@The table below briefly describes the tasks you must complete to install PHD. Each task is explained in more detail in subsequent sections; click the task name to jump to those sections. Step Task...";
fil["203"]= "topics/PHDInstallationPrerequisites.html@@@PHD Pre-Install@@@This section provides information you ll need, as well as tasks that must be completed, before you install PHD...";
fil["204"]= "topics/PHDInstallationandAdministration.html@@@PHD Installation and Administration@@@This document describes how to install and administer Pivotal HD Enterprise using the Command-Line Interface (CLI) for Pivotal Command Center. In addition, the document provides an overview of Pivotal...";
fil["205"]= "topics/PHDJAVAJDK.html@@@PHD Pre-Inst 2 - JAVA JDK@@@Before you begin your installation, ensure that you are running Oracle JAVA JDK version 1.7 on the Admin node and that you are not running OpenJDK as your default JDK. Note: Version 1.7 is required...";
fil["206"]= "topics/PHDPostInstallation.html@@@PHD Post-Install@@@This section describes tasks you perform after installing PHD...";
fil["207"]= "topics/PHDPrerequisiteChecklist.html@@@PHD Pre-Install Checklist@@@The following tasks need to be completed before you begin your PHD installation. Each task is explained in more detail in subsequent sections; click the task name to jump to those sections. Step Task...";
fil["208"]= "topics/PHDRESTAPIs.html@@@PHD REST API@@@This section describes how to access PHD s REST API via Swagger. Note: The HAWQ API is currently being re-developed. As of now this API is not functional...";
fil["209"]= "topics/PHDServicesReference.html@@@PHD Services Reference@@@Overriding Directory Permissions On the Local Filesystem On HDFS Pivotal HD Users and Groups Pivotal HD Ports The following table shows the list of directories that Pivotal HD overrides with specific...";
fil["210"]= "topics/PHDTroubleshooting.html@@@PHD Troubleshooting@@@This section provides common errors you may receive and how to troubleshoot or workaround those errors. Debugging Errors Pivotal HD Installation Cluster Deployment Cluster Nodes Installation Services...";
fil["211"]= "topics/PHDTurnOffiptables.html@@@PHD Pre-Inst 4 - Turn Off iptables@@@Before you begin your installation, verify that iptables is turned off: As root , run: # chkconfig iptables off # service iptables stop Next Task: PHD Pre-Inst 5 - Disable SELinux...";
fil["212"]= "topics/PHDUpgradeChecklist20xto210.html@@@2.0.x to 2.1.0 - Upgrade Checklist@@@Note: Before you start your upgrade; make sure you have met all the upgrade prerequisites (see Pre-Upgrade Checklist ). The table below briefly describes the tasks you must complete to upgrade PHD...";
fil["213"]= "topics/PHDUpgradePrerequisites.html@@@PHD Pre-Upgrade@@@This section provides information you ll need, as well as tasks that must be completed, before you upgrade PHD...";
fil["214"]= "topics/PHDVerifyPackageAccessibility.html@@@PHD Pre-Inst 3 - Verify Package Accessibility@@@Verify that all packages are available in a local yum repository or that you have yum access to an EPEL yum repository. Pivotal Command Center and Pivotal HD Enterprise expect some prerequisite...";
fil["215"]= "topics/PREPARE.html@@@PREPARE@@@Prepare a statement for execution. Synopsis PREPARE name [ ( datatype [, ...] ) ] AS statement Description PREPARE creates a prepared statement, possibly with unbound parameters. A prepared statement...";
fil["216"]= "topics/PXFExternalTableandAPIReference.html@@@PXF External Table and API Reference@@@The Java API lets you extend PXF functionality and add new services and formats without changing HAWQ. The API includes four classes: Fragmenter, Accessor, Resolver, and Analyzer. The Fragmenter...";
fil["217"]= "topics/PXFInstallationandAdministration.html@@@PXF Installation and Administration@@@PXF is an extensible framework that allows HAWQ to query external system data. PXF includes built-in connectors for accessing data that exists inside HDFS files, Hive tables, and HBase tables. Users...";
fil["218"]= "topics/Pig.html@@@Pig@@@About Pig Installing Pig Prerequisites Pig RPM Packages Pig Client Setup Pig Configuration Using Pig Using Pig with Hbase Using Pig with Piggybank/Hive Pig is a high-level data-flow language and...";
fil["219"]= "topics/PivotalCommandCenter.html@@@Pivotal Command Center@@@Pivotal Command Center (PCC) is a multi-tier graphical web application that allows you to configure, deploy, monitor, and manage your Pivotal HD clusters. PCC enables administrators to view aggregated...";
fil["220"]= "topics/PivotalExtensionFrameworkPXF.html@@@Pivotal Extension Framework (PXF)@@@This guide provides information for system administrators and application developers responsible for installing and customizing HAWQ using Pivotal Extension Framework (PXF). This guide provides...";
fil["221"]= "topics/PivotalHAWQ.html@@@Pivotal HAWQ@@@Pivotal HAWQ extends Pivotal HD Enterprise, adding rich, proven parallel SQL processing facilities. These SQL processing facilities enhance productivity, rendering Hadoop queries faster than any...";
fil["222"]= "topics/PivotalHD.html@@@Pivotal HD@@@Pivotal HD Enterprise is an enterprise-capable, commercially supported distribution of Apache Hadoop 2.2 packages targeted to traditional Hadoop deployments. Pivotal HD Enterprise enables you to take...";
fil["223"]= "topics/PivotalHadoopEnhancements.html@@@Pivotal Hadoop Enhancements@@@Pivotal HD is a full Apache Hadoop distribution with Pivotal add-ons and a native integration with the Pivotal Greenplum database. HDFS Off-Cluster Client Rack Awareness Overview of Rack Awareness...";
fil["224"]= "topics/PlanningyourPHDClusterDeployment.html@@@Planning your PHD Cluster Deployment@@@Before deploying a Hadoop cluster, Pivotal recommends that you consider the following: Select the appropriate hardware configuration for your Admin and cluster nodes. Map Hadoop services roles to...";
fil["225"]= "topics/PostInstallationReferenceInformation.html@@@Post-Install Reference Information@@@This section provides reference information you might find useful after you ve installed PHD. Pivotal HD Directory Layout SSL Certificates Cluster Configuration Template Example The * indicates...";
fil["226"]= "topics/PreparingtoInstallHAWQ.html@@@Preparing to Install HAWQ@@@This document describes how to install HAWQ manually. HAWQ can be installed along with Pivotal HD Enterprise using the Command-Line Interface (CLI). However, if you choose to not install HAWQ using...";
fil["227"]= "topics/REASSIGN-OWNED.html@@@REASSIGN OWNED@@@Changes the ownership of database objects owned by a database role. Synopsis REASSIGN OWNED BY old_role [, ...] TO new_role Description REASSIGN OWNED reassigns all the objects in the current database...";
fil["228"]= "topics/RELEASE-SAVEPOINT.html@@@RELEASE SAVEPOINT@@@Destroys a previously defined savepoint. Synopsis RELEASE [SAVEPOINT] savepoint_name Description RELEASE SAVEPOINT destroys a savepoint previously defined in the current transaction. Destroying...";
fil["229"]= "topics/RESET.html@@@RESET@@@Restores the value of a system configuration parameter to the default value. Synopsis RESET configuration_parameter RESET ALL Description RESET restores system configuration parameters to their...";
fil["230"]= "topics/REVOKE.html@@@REVOKE@@@Removes access privileges. Synopsis REVOKE [GRANT OPTION FOR] { {SELECT | INSERT | UPDATE | DELETE        | REFERENCES | TRIGGER | TRUNCATE } [,...] | ALL [PRIVILEGES] }        ON [TABLE] tablename...";
fil["231"]= "topics/ROLLBACK-TO-SAVEPOINT.html@@@ROLLBACK TO SAVEPOINT@@@Rolls back the current transaction to a savepoint. Synopsis ROLLBACK [WORK | TRANSACTION] TO [SAVEPOINT] savepoint_name Description This command will roll back all commands that were executed after...";
fil["232"]= "topics/ROLLBACK.html@@@ROLLBACK@@@Aborts the current transaction. Synopsis ROLLBACK [WORK | TRANSACTION] Description ROLLBACK rolls back the current transaction and causes all the updates made by the transaction to be discarded...";
fil["233"]= "topics/ReconfiguringaCluster.html@@@Reconfiguring a Cluster@@@Run the icm_client reconfigure command to update specific configurations for an existing cluster. Some cluster-specific configurations cannot be updated: Note: Reconfiguring the topology of a cluster...";
fil["234"]= "topics/ReplacingtheSlaveNode.html@@@Replacing the Slave Node@@@There are many situations in which a slave node goes down and the entire server must be replaced.  In these cases, the administrator is not able to issue a decommission, so HDFS will mark the server...";
fil["235"]= "topics/ReplacingtheSlaveNodeDisk.html@@@Replacing the Slave Node Disk@@@Hadoop is extremely resilient in terms of hardware failure, but disk failure is one type of failure scenario that relies on the administrator to put some thought into as the system is configured. In...";
fil["236"]= "topics/RestartingaCluster.html@@@Restarting a Cluster@@@You can use the icm_client restart command to stop, then restart, a cluster. See Starting a Cluster and Stopping a Cluster for more details about the stop/start operations. Syntax [gpadmin...";
fil["237"]= "topics/RetrievingInformationaboutaDeployedCluster.html@@@Retrieving Information about a Deployed Cluster@@@Run the icm_client fetch-configuration command to fetch the configurations for an existing cluster and store them in a local file system directory. Syntax icm_client fetch-configuration -h Usage...";
fil["238"]= "topics/RunningPHDSamplePrograms.html@@@Running PHD Sample Programs@@@Make sure you are logged in as user gpadmin on the appropriate host before testing any of the services. Testing Hadoop Testing YARN Testing Zookeeper Testing HBase and ZooKeeper Testing HAWQ Testing...";
fil["239"]= "topics/SAVEPOINT.html@@@SAVEPOINT@@@Defines a new savepoint within the current transaction. Synopsis SAVEPOINT savepoint_name Description SAVEPOINT establishes a new savepoint within the current transaction. A savepoint is a special...";
fil["240"]= "topics/SELECT-INTO.html@@@SELECT INTO@@@Defines a new table from the results of a query. Synopsis SELECT [ALL | DISTINCT [ON ( expression [, ...] )]] * | expression [AS output_name ] [, ...] INTO [TEMPORARY | TEMP] [TABLE] new_table [FROM...";
fil["241"]= "topics/SELECT.html@@@SELECT@@@Retrieves rows from a table or view. Synopsis SELECT [ALL | DISTINCT [ON ( expression [, ...])]]   * | expression [[AS] output_name ] [, ...]   [FROM from_item [, ...]]   [WHERE condition ]   [GROUP...";
fil["242"]= "topics/SET-ROLE.html@@@SET ROLE@@@Sets the current role identifier of the current session. Synopsis SET [SESSION | LOCAL] ROLE rolename SET [SESSION | LOCAL] ROLE NONE RESET ROLE Description This command sets the current role...";
fil["243"]= "topics/SET-SESSION-AUTHORIZATION.html@@@SET SESSION AUTHORIZATION@@@Sets the session role identifier and the current role identifier of the current session. Synopsis SET [SESSION | LOCAL] SESSION AUTHORIZATION rolename SET [SESSION | LOCAL] SESSION AUTHORIZATION...";
fil["244"]= "topics/SET.html@@@SET@@@Changes the value of a HAWQ configuration parameter. Synopsis SET [SESSION | LOCAL] configuration_parameter {TO | =} value |   value   | DEFAULT} SET [SESSION | LOCAL] TIME ZONE { timezone | LOCAL...";
fil["245"]= "topics/SHOW.html@@@SHOW@@@Shows the value of a system configuration parameter. Synopsis SHOW configuration_parameter SHOW ALL Description SHOW displays the current settings of HAWQ system configuration parameters. These...";
fil["246"]= "topics/SQLCommandReference.html@@@SQL Command Reference@@@This section contains a description and the syntax of the SQL commands supported by HAWQ...";
fil["247"]= "topics/SecureModeCommands.html@@@Enabling Secure Mode Commands@@@HDFS commands need a Kerberos ticket when running in secure mode. To check if you have a valid ticket, run klist : [gpadmin@client ~]$ klist Ticket cache: FILE:/tmp/krb5cc_500 Default principal...";
fil["248"]= "topics/SecureWebAccess.html@@@Secure Web Access@@@This section describes how to configure WebHDFS on a secure PHD cluster. Overview Prerequisites Configuring Secure WebHDFS Create a Principal Add to Groups Using WebHDFS in Secure Mode Authenticate...";
fil["249"]= "topics/SecureWebAccessviaHttpFS.html@@@Secure Web Access via HttpFS@@@HttpFS is another set of RESTful APIs that enable you to operate HDFS via the HTTP protocol. It has APIs that are compatible with WebHDFS. You also need to make some configuration changes to make it...";
fil["250"]= "topics/Security.html@@@Security@@@This section describes how to secure a PHD cluster, including configuring Kerberos and LDAP authentication, and enabling auditing...";
fil["251"]= "topics/SecurityKerberosAuthentication.html@@@Security/Kerberos Authentication@@@This section describes how to enable/disable Kerberos authentication for PHD clusters. Kerberos is a network authentication protocol that provides strong authentication for client/server applications...";
fil["252"]= "topics/SecurityOverview.html@@@Security Overview@@@Starting with PHD 2.1, security setup for components installed via the Pivotal Command Center (PCC/ICM) is done as part of the installation process. For details, see the PHD Installation and...";
fil["253"]= "topics/SecurityTroubleshooting.html@@@Security - Troubleshooting@@@Log Files A good first step is to look for exceptions that may give you a clue as to the problem in the log files (where hostname is the host where the log file is located): namenode...";
fil["254"]= "topics/ShrinkingaCluster.html@@@Shrinking a Cluster@@@Note: Make sure you decommission the slave hosts (see Decommissioning Slave Nodes ) prior to removing them, to avoid potential data loss. Shrink a cluster by running the icm_client remove-slaves...";
fil["255"]= "topics/ShuttingDowntheSlaveNode.html@@@Shutting Down the Slave Node@@@Previous Step: Decommissioning the YARN NodeManager Once the slave nodes have been decommissioned, the slave processes running on the newly decommissioned nodes need to be shutdown via the Pivotal...";
fil["256"]= "topics/Sqoop.html@@@Sqoop@@@About Sqoop Installing Sqoop Prerequisites Sqoop RPM Packages Sqoop Client Setup Sqoop Metastore Setup Sqoop Metastore Configuration Using Sqoop Starting/Stopping Sqoop Metastore Server Starting Sqoop...";
fil["257"]= "topics/StackandToolsReference.html@@@Stack and Tools Reference@@@This document includes manual installation and upgrade instructions for RPM and binary distributions of PHD components as well as instructions for manually securing your cluster via Kerberos...";
fil["258"]= "topics/StartingHAWQ.html@@@Starting HAWQ@@@Note that starting and stopping HAWQ can only be initiated directly on the HAWQ Master. More information about HAWQ can be found in the HAWQ Installation Guide and the HAWQ Administrator Guide...";
fil["259"]= "topics/StartingStoppingandUninstallingaCluster.html@@@Starting, Stopping, and Uninstalling a Cluster@@@These functions are only available to administrative users. In addtion, depending on the state of the cluster, some of these buttons will be enabled while others are disabled. To start a cluster: From...";
fil["260"]= "topics/StartingaCluster.html@@@Starting a Cluster@@@You can use the icm_client start command to: Start all the configured services of the cluster. Start individual services configured for the cluster. Start individual roles on a specific set of...";
fil["261"]= "topics/StartingtheCluster.html@@@PHD Install 8 - Start the Cluster@@@As gpadmin , use icm_client to start your cluster. For example: $ icm_client start -l &lt;CLUSTERNAME&gt; See Starting a Cluster for more detailed instructions and other startup options. Next Task: If you...";
fil["262"]= "topics/StartingtheClusterfromtheUI.html@@@Start the Cluster from the UI@@@To start your cluster; click Actions : Start on the Cluster Status page...";
fil["263"]= "topics/StoppingHAWQ.html@@@Stopping HAWQ@@@Note that starting and stopping HAWQ can only be initiated directly on the HAWQ Master. More information about HAWQ can be found in the HAWQ Installation Guide and the HAWQ Administrator Guide...";
fil["264"]= "topics/StoppingaCluster.html@@@Stopping a Cluster@@@You can use the icm_client stop command to stop an entire cluster, to stop a single service, and to stop a single role on a specific set of hosts on which it is configured. The command stops all...";
fil["265"]= "topics/SudoConfigurationFile.html@@@sudo Configuration File@@@The sudo configurations in /etc/sudoers.d/gpadmin are used by the gpadmin user to perform deployments and upgrades. This sudo configuration file is automatically created as part of the preparehosts...";
fil["266"]= "topics/SudoConfigurationFiles.html@@@sudo Configuration Files@@@The sudo configurations in /etc/sudoers.d/gpadmin are used for the gpadmin user to perform deployments and upgrades. This sudo configuration file is automatically created as part of the preparehosts...";
fil["267"]= "topics/Summary.html@@@8. Summary@@@Once your cluster has successfully deployed, you can view a summary of the cluster, as shown here: Once you have reviewed this summary, click Status , to return to the Cluster Status page. Your new...";
fil["268"]= "topics/SupportedPlatformsandBrowsers.html@@@Supported Platforms and Browsers@@@The following platforms and browsers are supported: RHEL 6.4 64-bit, 6.5 64-bit CentOS 6.4 64-bit, 6.5 64-bit (Minimum screen resolution: 1280 x 800) Firefox 23 IE 10 Chrome 33.0.1750.146...";
fil["269"]= "topics/SwaggerwithOAuth.html@@@Swagger with OAuth@@@This topic contains instructions for using Swagger for PHD APIs using OAuth authentication. Swagger is a specification and complete framework implementation for describing, producing, consuming, and...";
fil["270"]= "topics/SystemCatalogReference.html@@@System Catalog Reference@@@This is a reference of the system catalog tables and views of the HAWQ Database. All system tables related to the parallel features of HAWQ are prefixed with gp_  . Tables prefixed with pg_ are...";
fil["271"]= "topics/TRUNCATE.html@@@TRUNCATE@@@Empties a table of all rows. Synopsis TRUNCATE [TABLE] name [, ...] [CASCADE | RESTRICT] Description TRUNCATE quickly removes all rows from a table or set of tables.This is most useful on large...";
fil["272"]= "topics/Topology.html@@@Topology@@@This screen shows you the basic topology of your cluster.  You can also add/remove slaves to/from the cluster via this screen. The main portion of this page displays a list of all the nodes in your...";
fil["273"]= "topics/UninstallingPCC.html@@@Uninstalling PCC@@@Follow the steps below to uninstall Pivotal Command Center and your Pivotal HD cluster: As gpadmin , stop services on all your clusters (See the Pivotal HD Installation and Administrator Guide for...";
fil["274"]= "topics/UninstallingaCluster.html@@@Uninstalling a Cluster@@@Use icm_client uninstall to uninstall a cluster. You must run the icm_client stop command to stop running clusters before running the icm_client uninstall command. You must also ensure that HAWQ has...";
fil["275"]= "topics/UpgradeChecklist111to210.html@@@1.1.1 to 2.1.0 - Upgrade Checklist@@@Note: Before you start your upgrade; make sure you have met all the upgrade prerequisites (see Pre-Upgrade Checklist ). The table below briefly describes the tasks you must complete to upgrade PHD...";
fil["276"]= "topics/UpgradeInstructions111to210.html@@@1.1.1 to 2.1.0 - Upgrade Instructions@@@Note: Before you start your upgrade; make sure you have met all the upgrade prerequisites (see Pre-Upgrade Checklist ). Follow the instructions below to upgrade your PHD system from 1.1.1 to 2.1...";
fil["277"]= "topics/UpgradeInstructions20xto210.html@@@2.0.x to 2.1.0 - Upgrade Instructions@@@Note: Before you start your upgrade; make sure you have met all the upgrade prerequisites (see Pre-Upgrade Checklist ). Follow the instructions below to upgrade PHD 2.0.1 to PHD 2.1.0: Verify the...";
fil["278"]= "topics/UpgradePrerequisiteChecklist.html@@@Pre-Upgrade Checklist@@@The following tasks need to be completed before you upgrade PHD. Each task is explained in more detail in subsequent sections; click the task name to jump to those sections. Step Task Description...";
fil["279"]= "topics/UpgradeReferenceInformation111to210.html@@@1.1.1 to 2.1.0 - Upgrade Reference Information@@@Upgrade Syntax Changed Configuration Parameters and Files For reference, the complete syntax for the upgrade command is as follows: [gpadmin]# icm_client upgrade --help Usage: /usr/bin/icm_client...";
fil["280"]= "topics/UpgradeReferenceInformation20xto210.html@@@2.0.x to 2.1.0 - Upgrade Reference Information@@@Upgrade Syntax Changed Configuration Parameters and Files For reference, the complete syntax for the upgrade command is as follows: [gpadmin]# icm_client upgrade --help Usage: /usr/bin/icm_client...";
fil["281"]= "topics/UpgradingHAWQandComponents.html@@@Upgrading HAWQ and the HAWQ Components@@@This section describes how to upgrade HAWQ and its components if installed manually. Note: Follow these instructions if you installed HAWQ manually. If you installed HAWQ using the PHD Manager...";
fil["282"]= "topics/UpgradingPCC.html@@@Upgrading PCC@@@The following instructions are for upgrading Pivotal Command Center from version 2.2.x to 2.3. Note: Upgrade Notes If you are upgrading to a new version of Pivotal Command Center, make sure you are...";
fil["283"]= "topics/UpgradingPHD20xto210.html@@@Upgrading PHD 2.0.x to 2.1.0@@@This section describes how to upgrade Pivotal HD using Pivotal Command Center s command line interface (CLI...";
fil["284"]= "topics/UpgradingPHDfrom111to210.html@@@Upgrading PHD 1.1.1 to 2.1.0@@@This section describes how to upgrade Pivotal HD using Pivotal Command Center s command line interface (CLI...";
fil["285"]= "topics/UsingHAWQtoQueryData.html@@@Using HAWQ to Query Data@@@This chapter describes the use of the SQL language in Pivotal HAWQ Database. SQL commands are typically entered using the standard PostgreSQL interactive terminal psql , but other programs that have...";
fil["286"]= "topics/UsingPCC.html@@@Using PCC@@@This section provides instructions for using the PCC UI...";
fil["287"]= "topics/UsingProceduralLanguages.html@@@Using Procedural Languages@@@HAWQ allows user-defined functions to be written in other languages besides SQL and C. These other languages are generically called procedural languages (PLs). For a function written in a procedural...";
fil["288"]= "topics/VACUUM.html@@@VACUUM@@@Garbage-collects and optionally analyzes a database. Synopsis VACUUM [FULL] [FREEZE] [VERBOSE] [ table ] VACUUM [FULL] [FREEZE] [VERBOSE] ANALYZE               [ table [( column...";
fil["289"]= "topics/Validation.html@@@6. Validation@@@The Validation screen opens. If the configuration has errors they will be displayed here; otherwise you will see post-deployment instructions. Click Deploy . Next Step: 7. Deployment Status...";
fil["290"]= "topics/VerifyJavaJDK.html@@@Pre-Upgrade 2 - Verify Java JDK@@@Ensure that you are running Oracle JAVA JDK version 1.7 as the default JDK on the Admin node. Note: This is a new requirement; prior to PHD 2.0, JDK 1.6 was also supported. Instructions below. Note...";
fil["291"]= "topics/VerifyingPHDServiceStatus.html@@@Verifying PHD Service Status@@@You can use the service status command to check the running status of a particular service role from its appropriate host(s). Refer to Running PHD Sample Programs where you can see the sample...";
fil["292"]= "topics/VersionsServicesandHosts.html@@@2. Versions, Services, and Hosts@@@The Versions, Services & Hosts screen opens. Note: Hosts can be entered individually, newline-separated; or can be expressed in a range, for example host[1-5].yourdomain.com .  They can also be...";
fil["293"]= "topics/YarnAppMonitor.html@@@Yarn App Monitor@@@The YARN App Monitor screen tracks YARN applications that are executed in the Pivotal HD Cluster. The YARN applications displayed can be filtered by category and/or time range: By Category: all apps...";
fil["294"]= "topics/Zookeeper.html@@@Zookeeper@@@About Zookeeper Installing Zookeeper Zookeeper RPM Packages Zookeeper Server Setup Zookeeper Client Setup Zookeeper Configuration Using Zookeeper Starting the Zookeeper Daemon Accessing the Zookeeper...";
fil["295"]= "topics/createdb.html@@@createdb@@@Creates a new database. Synopsis createdb [ connection_option ...] [ -D tablespace ] [ -E encoding ] [ -O owner ] [ -T template ] [ -e ] [ dbname [  description  ]] createdb --help createdb --version...";
fil["296"]= "topics/createlang.html@@@createlang@@@Defines a new procedural language for a database. Synopsis createlang [ connection_option ...] [ -e ] langname [[ -d ] dbname ] createlang [ connection-option ...] -l dbname createlang --help...";
fil["297"]= "topics/createuser.html@@@createuser@@@Creates a new database role. Synopsis createuser [ connection_option ...] [ role_attribute ...] [ -e ] role_name createuser --help | --version Description createuser creates a new HAWQ role. You must...";
fil["298"]= "topics/dropdb.html@@@dropdb@@@Removes a database. Synopsis dropdb [ connection_option ...] [ -e ] [ -i ] dbname dropdb --help dropdb --version Description dropdb removes an existing database. The user who executes this command...";
fil["299"]= "topics/dropuser.html@@@dropuser@@@Removes a database role. Synopsis dropuser [ connection_option ...] [ -e ] [ -i ] role_name dropuser --help dropuser --version Description dropuser removes an existing role from HAWQ.. Only superusers...";
fil["300"]= "topics/gpactivatestandby.html@@@gpactivatestandby@@@Activates a standby master host and makes it the active master for the HAWQ system. Synopsis gpactivatestandby -d standby_master_datadir [ -c new_standby_master ] [ -f ] [ -a ] [ -q ] [ -l...";
fil["301"]= "topics/gpcheckperf.html@@@gpcheckperf@@@Verifies the baseline hardware performance of the specified hosts. Synopsis gpcheckperf -d test_directory [ -d test_directory ...]     { -f hostfile_gpcheckperf | - h hostname [ -h hostname...";
fil["302"]= "topics/gpconfig.html@@@gpconfig@@@Sets server configuration parameters on all segments within a HAWQ system. Synopsis gpconfig -c param_name -v value [ -m master_value | --masteronly ]        | -r param_name [ --masteronly | -l...";
fil["303"]= "topics/gpexpand.html@@@gpexpand@@@Expands an existing HAWQ database across new hosts in the array. Synopsis gpexpand [ -f hosts_file ]        | -i input_file [ -B batch_size ] [ -V ]       | { -d hh:mm:ss | -e   YYYY-MM-DD hh:mm:ss...";
fil["304"]= "topics/gpextract.html@@@gpextract@@@Extracts the metadata of a specified table into a YAML file. Synopsis gpextract [ -h hostname] [ -p port] [ -U username] [ -d database] [ -o output_file] [ -W ] &lt;tablename&gt; gpextract -? gpextract...";
fil["305"]= "topics/gpfdist.html@@@gpfdist@@@Serves data files to or writes data files out from HAWQ segments. Synopsis gpfdist [ -d directory ] [ -p http_port ] [ -l log_file ] [ -t timeout ] [ -S ] [ -v | -V ] [ -m max_length ] [ --ssl...";
fil["306"]= "topics/gpfilespace.html@@@gpfilespace@@@Creates a filespace using a configuration file that defines per-segment file system locations. Filespaces describe the physical file system resources to be used by a tablespace. Synopsis gpfilespace...";
fil["307"]= "topics/gpinitstandby.html@@@gpinitstandby@@@Adds and/or initializes a standby master host for a HAWQ system. Synopsis gpinitstandby { -s standby_hostname | -r | -n } [ -M smart | -M fast] [ -a ] [ -q ] [ -D ] [ -L ] [ -l logfile_directory...";
fil["308"]= "topics/gpinitsystem.html@@@gpinitsystem@@@Initializes a HAWQ system using configuration parameters specified in the gpinitsystem_config file. Synopsis gpinitsystem -c gpinitsystem_config [ -h hostfile_gpinitsystem ] [ -B parallel_processes...";
fil["309"]= "topics/gpload.html@@@gpload@@@Runs a load job as defined in a YAML formatted control file. Synopsis gpload -f control_file [ -l log_file ] [ -h hostname ] [ -p port ] [ -U username ] [ -d database ] [ -W ] [ --gpfdist_timeout...";
fil["310"]= "topics/gplogfilter.html@@@gplogfilter@@@Searches through HAWQ log files for specified entries. Synopsis gplogfilter [ timestamp_options ] [ pattern_options ] [ output_options ] [ input_options ] [ input_file ] gplogfilter --help gplogfilter...";
fil["311"]= "topics/gpmigrator.html@@@gpmigrator@@@Upgrades an existing HAWQ 1.1.x system to 1.2.x. Synopsis gpmigrator old_GPHOME_path new_GPHOME_path            [ -d master_data_directory ]            [ -l logfile_directory ] [ -q ] [ --debug...";
fil["312"]= "topics/gppkg.html@@@gppkg@@@Installs HAWQ extensions such as pgcrypto, PL/R, PL/Java, and MADlib, along with their dependencies, across an entire cluster. Synopsis gppkg [ -i package | -u package | -r name - version | -c ] [ -d...";
fil["313"]= "topics/gprecoverseg.html@@@gprecoverseg@@@Recovers a primary or mirror segment instance that has been marked as down. Synopsis gprecoverseg [ -p new_recover_host [,...]] [ -d master_data_directory ] [ -B parallel_processes ] gprecoverseg...";
fil["314"]= "topics/gpscp.html@@@gpscp@@@Copies files between multiple hosts at once. Synopsis gpscp { -f hostfile_gpssh | -h hostname [ -h hostname ...] } [ -J character ] [ -v ] [[ user @] hostname :] file_to_copy [...] [[ user @] hostname...";
fil["315"]= "topics/gpssh-exkeys.html@@@gpssh-exkeys@@@Exchanges SSH public keys between hosts. Synopsis gpssh-exkeys -f hostfile_exkeys | - h hostname [ -h hostname ...] [ -p &lt;password&gt; ] gpssh-exkeys -e hostfile_exkeys -x hostfile_gpexpand gpssh-exkeys...";
fil["316"]= "topics/gpssh.html@@@gpssh@@@Provides SSH access to multiple hosts at once. Synopsis gpssh { -f hostfile_gpssh | - h hostname [ -h hostname ...] } [ -u userid ...] [ -v ] [ -e ] [ bash_command ] gpssh -? gpssh --version...";
fil["317"]= "topics/gpstart.html@@@gpstart@@@Starts a HAWQ system. Synopsis gpstart [ -d master_data_directory ] [ -B parallel_processes ] [ -R ] [ -m ] [ -y ] [ -a ] [ -t timeout_seconds ] [ -l logfile_directory ] [ -v | -q ] gpstart -? | -h...";
fil["318"]= "topics/gpstate.html@@@gpstate@@@Shows the status of a running HAWQ system. Synopsis gpstate [ -d master_data_directory ] [ -B parallel_processes ] [ -s | -b | -Q ] [ -p ] [ -i ] [ -f ] [ -v | -q ] [ -l log_directory ] gpstate...";
fil["319"]= "topics/gpstop.html@@@gpstop@@@Stops or restarts a HAWQ system. Synopsis gpstop [ -d master_data_directory ] [ -B parallel_processes ] [ -M smart | fast | immediate] [ -t timeout_seconds ] [ -r ] [ -y ] [ -a ] [ -l...";
fil["320"]= "topics/hawq_toolkitReference.html@@@hawq_toolkit Reference@@@This chapter describes the hawq_toolkit administrative schema views and their usage. What is hawq_toolkit? Viewing HAWQ Database Server Log Files hawq_log_command_timings hawq_log_database...";
fil["321"]= "topics/pg_dump.html@@@pg_dump@@@Extracts a database into a single script file or other archive file. Synopsis pg_dump [ connection_option ...] [ dump_option ...] dbname Description pg_dump is a standard client utility for backing up...";
fil["322"]= "topics/pg_dumpall.html@@@pg_dumpall@@@Extracts all databases in a HAWQ system to a single script file or other archive file. Synopsis pg_dumpall [ connection_option ...] [ dump_option ...] Description pg_dumpall is a standard client...";
fil["323"]= "topics/pg_restore.html@@@pg_restore@@@Restores a database from an archive file created by pg_dump . Synopsis pg_restore [ connection_option ...] [ restore_option ...] filename Description pg_restore is a utility for restoring a database...";
fil["324"]= "topics/psql.html@@@psql@@@Interactive command-line interface for HAWQ Synopsis psql [ option ...] [ dbname [ username ]] Description psql is a terminal-based front-end to HAWQ. It enables you to type in queries interactively...";
fil["325"]= "topics/vacuumdb.html@@@vacuumdb@@@Garbage-collects and analyzes a database. Synopsis vacuumdb [ connection-option ...] [--full | -f] [ -F ] [ --verbose | -v ] [ --analyze | -z ] [ --table | -t table [( column [,...] )] ] [ dbname...";
